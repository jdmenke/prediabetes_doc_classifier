{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e91bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "import transformers\n",
    "from transformers import Trainer, AutoModel, AutoTokenizer, AutoModelForSequenceClassification, set_seed\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback, BioGptForSequenceClassification, get_scheduler\n",
    "import datasets\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.utils.checkpoint\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import wandb\n",
    "\n",
    "from torch import cuda\n",
    "DEVICE = torch.device('cuda' if cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda' if cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba08bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec935da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoemenke\u001b[0m (\u001b[33mnlp4health\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2e1a8",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b49d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahn 2018</td>\n",
       "      <td>The risk for coronary heart disease in women s...</td>\n",
       "      <td>[0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ares 2019</td>\n",
       "      <td>Age- and sex-stratified hazard ratios (HRs) we...</td>\n",
       "      <td>[1, 1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barr 2007</td>\n",
       "      <td>Known diabetes mellitus (HR 2.6 95% CI 1.4 to ...</td>\n",
       "      <td>[1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barzilay 1999</td>\n",
       "      <td>The new fasting American Diabetes Association ...</td>\n",
       "      <td>[1, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bergman 2015</td>\n",
       "      <td>Prediabetes comprising impaired fasting glucos...</td>\n",
       "      <td>[1, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Wen 2005</td>\n",
       "      <td>RESULTS: FBG &gt; or =110 mg/dl was associated wi...</td>\n",
       "      <td>[0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Wild 2005</td>\n",
       "      <td>RESULTS: Prevalence of undiagnosed diabetes us...</td>\n",
       "      <td>[1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Yeboah 2011</td>\n",
       "      <td>Type 2 DM was defined as fasting glucose &gt;125 ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Zhang 2008</td>\n",
       "      <td>Hypertension was defined by the criteria of th...</td>\n",
       "      <td>[1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>de Abreu 2017</td>\n",
       "      <td>AIMS: Impaired fasting glucose (IFG) and diabe...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                                               text  \\\n",
       "0         Ahn 2018  The risk for coronary heart disease in women s...   \n",
       "1        Ares 2019  Age- and sex-stratified hazard ratios (HRs) we...   \n",
       "2        Barr 2007  Known diabetes mellitus (HR 2.6 95% CI 1.4 to ...   \n",
       "3    Barzilay 1999  The new fasting American Diabetes Association ...   \n",
       "4     Bergman 2015  Prediabetes comprising impaired fasting glucos...   \n",
       "..             ...                                                ...   \n",
       "125       Wen 2005  RESULTS: FBG > or =110 mg/dl was associated wi...   \n",
       "126      Wild 2005  RESULTS: Prevalence of undiagnosed diabetes us...   \n",
       "127    Yeboah 2011  Type 2 DM was defined as fasting glucose >125 ...   \n",
       "128     Zhang 2008  Hypertension was defined by the criteria of th...   \n",
       "129  de Abreu 2017  AIMS: Impaired fasting glucose (IFG) and diabe...   \n",
       "\n",
       "              labels  \n",
       "0    [0, 1, 1, 0, 0]  \n",
       "1    [1, 1, 0, 1, 0]  \n",
       "2    [1, 0, 1, 0, 0]  \n",
       "3    [1, 1, 1, 0, 0]  \n",
       "4    [1, 1, 0, 0, 0]  \n",
       "..               ...  \n",
       "125  [0, 1, 1, 0, 0]  \n",
       "126  [1, 0, 1, 0, 0]  \n",
       "127  [0, 1, 0, 0, 0]  \n",
       "128  [1, 0, 1, 0, 0]  \n",
       "129  [0, 1, 0, 0, 0]  \n",
       "\n",
       "[130 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/doc_summary_predictions.csv')\n",
    "\n",
    "# Extracted text\n",
    "def_df = df[df['prediction'] == 1]\n",
    "def_df = def_df[['text', 'name']]\n",
    "def_df['name'] = def_df['name'].apply(lambda s: s.replace('_', ' ').replace('.txt', ''))\n",
    "def_df = def_df.groupby('name')['text'].apply(' '.join).reset_index()\n",
    "def_df = def_df[['name', 'text']]\n",
    "\n",
    "# Meta-Analysis Labels\n",
    "label_df = pd.read_csv('data/labels_lenient.csv')\n",
    "label_df['Study'] = label_df['Study'].apply(lambda s: s.replace('_', ' ').replace('.txt', ''))\n",
    "\n",
    "# Merge text and labels\n",
    "label_df.rename(columns = {'Study':'name'}, inplace = True)\n",
    "merged_df = def_df.merge(label_df, how='inner', on='name')\n",
    "\n",
    "# Generate list of labels (igt, ifg-ada, ifg-who, hba1c-ada, hba1c-iec)\n",
    "merged_df['labels'] = merged_df[merged_df.columns[2:]].values.tolist()\n",
    "merged_df = merged_df.drop(columns=['gold_igt', 'gold_ifg_ada', 'gold_ifg_who', 'gold_hba1c_ada', 'gold_hba1c_iec']).reset_index(drop=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e99af95",
   "metadata": {},
   "source": [
    "## Model Development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0ce0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_multilabel_text(data_df, test_size):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        data_df: DataFrame with 'text' and 'labels' columns\n",
    "        test_size: [0,1]\n",
    "    Outputs:\n",
    "        train and test DataFrames with 'text' and 'labels' columns\n",
    "    \"\"\"\n",
    "    \n",
    "    data_df = data_df.reset_index()\n",
    "    data_df['index'] = data_df['index'].apply(lambda s: [s])\n",
    "    X = scipy.sparse.lil_matrix(data_df['index'].to_list())\n",
    "    y = scipy.sparse.lil_matrix(data_df['labels'].to_list())\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    y_train = pd.Series(pd.DataFrame.sparse.from_spmatrix(y_train).values.tolist()).rename('labels')\n",
    "    y_test = pd.Series(pd.DataFrame.sparse.from_spmatrix(y_test).values.tolist()).rename('labels')\n",
    "    \n",
    "    text_dict = data_df.to_dict()['text']\n",
    "    X_train = pd.DataFrame.sparse.from_spmatrix(X_train)[0].map(text_dict).rename('text')\n",
    "    X_test = pd.DataFrame.sparse.from_spmatrix(X_test)[0].map(text_dict).rename('text')\n",
    "    \n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d428f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset, tokenizer, max_length):\n",
    "    dataset = datasets.Dataset.from_pandas(dataset[['text', 'labels']], preserve_index=False)\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding='max_length', truncation=True, max_length=max_length)\n",
    "    dataset_token = dataset.map(tokenize_function)\n",
    "    return dataset_token\n",
    "\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop('labels') #keeps the labels\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n",
    "                        labels.float().view(-1, self.model.config.num_labels))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def train_huggingface_model(output_dir, model_name, tokenizer, train_dataset, dev_dataset, num_labels, num_epochs, learning_rate, weight_decay, early_stop_var, grad_steps):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=num_labels,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "    ).to(device)\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    early_stop = EarlyStoppingCallback(early_stopping_patience = early_stop_var)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = output_dir,\n",
    "        evaluation_strategy = \"steps\",\n",
    "        logging_strategy = \"steps\",\n",
    "        logging_steps = STEPS,\n",
    "        eval_steps = STEPS,\n",
    "        per_device_train_batch_size = 1,\n",
    "        per_device_eval_batch_size = 1,\n",
    "        gradient_accumulation_steps = grad_steps,\n",
    "        gradient_checkpointing = True,\n",
    "        num_train_epochs = num_epochs,\n",
    "        learning_rate = learning_rate,\n",
    "        weight_decay = weight_decay,\n",
    "        load_best_model_at_end = True,\n",
    "        metric_for_best_model = 'macro F1',\n",
    "        report_to = \"wandb\",\n",
    "    )\n",
    "    \n",
    "    def compute_metrics(eval_preds):\n",
    "        all_labels = ['IGT', 'IFG_ADA', 'IFG_WHO', 'HbA1c_ADA', 'HbA1c_IEC']\n",
    "        predictions, labels = eval_preds\n",
    "        y_pred = torch.sigmoid(torch.from_numpy(predictions)) \n",
    "        y_pred = (y_pred.numpy()>0.5).astype(float)\n",
    "        clf_dict = metrics.classification_report(labels, y_pred, target_names=all_labels,\n",
    "                                         zero_division=0, output_dict=True)\n",
    "        return {\n",
    "            \"IGT P\": clf_dict['IGT']['precision'],\n",
    "            \"IGT R\": clf_dict['IGT']['recall'],\n",
    "            \"IGT F1\": clf_dict['IGT']['f1-score'],\n",
    "            \"IFG_ADA P\": clf_dict['IFG_ADA']['precision'],\n",
    "            \"IFG_ADA R\": clf_dict['IFG_ADA']['recall'],\n",
    "            \"IFG_ADA F1\": clf_dict['IFG_ADA']['f1-score'], \n",
    "            \"IFG_WHO P\": clf_dict['IFG_WHO']['precision'],\n",
    "            \"IFG_WHO R\": clf_dict['IFG_WHO']['recall'],\n",
    "            \"IFG_WHO F1\": clf_dict['IFG_WHO']['f1-score'], \n",
    "            \"HbA1c_ADA P\": clf_dict['HbA1c_ADA']['precision'],\n",
    "            \"HbA1c_ADA R\": clf_dict['HbA1c_ADA']['recall'],\n",
    "            \"HbA1c_ADA F1\": clf_dict['HbA1c_ADA']['f1-score'],\n",
    "            \"HbA1c_IEC P\": clf_dict['HbA1c_IEC']['precision'],\n",
    "            \"HbA1c_IEC R\": clf_dict['HbA1c_IEC']['recall'],\n",
    "            \"HbA1c_IEC F1\": clf_dict['HbA1c_IEC']['f1-score'],\n",
    "            \"micro F1\": clf_dict['micro avg']['f1-score'], \n",
    "            \"macro F1\": clf_dict['macro avg']['f1-score']\n",
    "        }\n",
    "    \n",
    "    trainer = MultiLabelTrainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_dataset,\n",
    "        eval_dataset = dev_dataset,\n",
    "        compute_metrics = compute_metrics,\n",
    "        callbacks = [early_stop],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.evaluate()\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927dfa6",
   "metadata": {},
   "source": [
    "### BERT-base-uncased (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d336178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "STEPS = 25 # change to 50\n",
    "NUM_LABELS = 5\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "OUTPUT_DIR = \"multilabel_bert_base_uncased\"\n",
    "MAX_LENGTH = 512\n",
    "EARLY_STOP_VAR = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.001\n",
    "NUM_EPOCHS = 25\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7f431b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tg8m42lb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ab73127d8a4ecebd331a0293f4a073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-surf-74</strong> at: <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/tg8m42lb' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/tg8m42lb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230525_111446-tg8m42lb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tg8m42lb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0631560815439dbb40a1f7afea3e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666815474939843, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joemenke/Final_Project/wandb/run-20230525_111736-rw8urt8l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/rw8urt8l' target=\"_blank\">genial-firebrand-75</a></strong> to <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/rw8urt8l' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/rw8urt8l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/rw8urt8l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1529551d7b20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Prediabetes Classification\",\n",
    "           config={\n",
    "               \"model\": MODEL_NAME,\n",
    "               \"max_length\": MAX_LENGTH,\n",
    "               \"epochs\": NUM_EPOCHS,\n",
    "               \"learning_rate\": LEARNING_RATE,\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5cc9aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN, TEST = stratify_multilabel_text(merged_df, test_size=0.33) # train/test split -> 77/33\n",
    "TRAIN, DEV = stratify_multilabel_text(TRAIN, test_size=0.33) # train/dev split -> 77/33\n",
    "\n",
    "train_dataset = preprocessing(TRAIN, TOKENIZER, MAX_LENGTH)\n",
    "dev_dataset = preprocessing(DEV, TOKENIZER, MAX_LENGTH)\n",
    "test_dataset = preprocessing(TEST, TOKENIZER, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "989d5a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/rw8urt8l?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x15295c4b0550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 01:09, Epoch 24/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Igt p</th>\n",
       "      <th>Igt r</th>\n",
       "      <th>Igt f1</th>\n",
       "      <th>Ifg Ada p</th>\n",
       "      <th>Ifg Ada r</th>\n",
       "      <th>Ifg Ada f1</th>\n",
       "      <th>Ifg Who p</th>\n",
       "      <th>Ifg Who r</th>\n",
       "      <th>Ifg Who f1</th>\n",
       "      <th>Hba1c Ada p</th>\n",
       "      <th>Hba1c Ada r</th>\n",
       "      <th>Hba1c Ada f1</th>\n",
       "      <th>Hba1c Iec p</th>\n",
       "      <th>Hba1c Iec r</th>\n",
       "      <th>Hba1c Iec f1</th>\n",
       "      <th>Micro f1</th>\n",
       "      <th>Macro f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.586430</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.269919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.581700</td>\n",
       "      <td>0.580416</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635659</td>\n",
       "      <td>0.404502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.552100</td>\n",
       "      <td>0.572754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.381533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.563401</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>0.377835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.566539</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.326651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.422900</td>\n",
       "      <td>0.559339</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.395097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>0.557581</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.372121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.389400</td>\n",
       "      <td>0.556406</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.366145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.359700</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.366145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>0.555584</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.369689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.360230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.557442</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.397863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.555106</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.587156</td>\n",
       "      <td>0.366270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "bert_model = train_huggingface_model(\n",
    "    OUTPUT_DIR,\n",
    "    MODEL_NAME,\n",
    "    TOKENIZER,\n",
    "    train_dataset, \n",
    "    dev_dataset, \n",
    "    NUM_LABELS, \n",
    "    NUM_EPOCHS,\n",
    "    LEARNING_RATE,\n",
    "    WEIGHT_DECAY,\n",
    "    EARLY_STOP_VAR, \n",
    "    GRAD_ACCUM_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979bc117",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.save_model(\"final_models/multilabel_bert_base_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a15d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1308253/2408855104.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  predictions = np.array(bert_model.predict(test_dataset))\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(bert_model.predict(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d25aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5277460813522339,\n",
       " 'test_IGT P': 0.52,\n",
       " 'test_IGT R': 0.6190476190476191,\n",
       " 'test_IGT F1': 0.5652173913043478,\n",
       " 'test_IFG_ADA P': 0.6153846153846154,\n",
       " 'test_IFG_ADA R': 1.0,\n",
       " 'test_IFG_ADA F1': 0.761904761904762,\n",
       " 'test_IFG_WHO P': 0.6363636363636364,\n",
       " 'test_IFG_WHO R': 0.7368421052631579,\n",
       " 'test_IFG_WHO F1': 0.6829268292682926,\n",
       " 'test_HbA1c_ADA P': 0.0,\n",
       " 'test_HbA1c_ADA R': 0.0,\n",
       " 'test_HbA1c_ADA F1': 0.0,\n",
       " 'test_HbA1c_IEC P': 0.0,\n",
       " 'test_HbA1c_IEC R': 0.0,\n",
       " 'test_HbA1c_IEC F1': 0.0,\n",
       " 'test_micro F1': 0.6257668711656442,\n",
       " 'test_macro F1': 0.40200979649548046,\n",
       " 'test_runtime': 0.5583,\n",
       " 'test_samples_per_second': 78.805,\n",
       " 'test_steps_per_second': 78.805}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a0ac4",
   "metadata": {},
   "source": [
    "### BigBird Roberta Base (try large if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4838d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "STEPS = 25 # change to 50\n",
    "NUM_LABELS = 5\n",
    "#MODEL_NAME = \"google/bigbird-roberta-base\"\n",
    "MODEL_NAME = \"google/bigbird-roberta-large\"\n",
    "OUTPUT_DIR = \"multilabel_bigbird_large\"\n",
    "MAX_LENGTH = 2554\n",
    "EARLY_STOP_VAR = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.001\n",
    "NUM_EPOCHS = 25\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195b71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joemenke/Final_Project/wandb/run-20230522_182531-cvqikmwd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/cvqikmwd' target=\"_blank\">fragrant-lake-70</a></strong> to <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/cvqikmwd' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/cvqikmwd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/cvqikmwd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x148c6330c100>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Prediabetes Classification\",\n",
    "           config={\n",
    "               \"model\": MODEL_NAME,\n",
    "               \"max_length\": MAX_LENGTH,\n",
    "               \"epochs\": NUM_EPOCHS,\n",
    "               \"learning_rate\": LEARNING_RATE,\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df284c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN, TEST = stratify_multilabel_text(merged_df, test_size=0.33) # train/test split -> 77/33\n",
    "TRAIN, DEV = stratify_multilabel_text(TRAIN, test_size=0.33) # train/dev split -> 77/33\n",
    "\n",
    "train_dataset = preprocessing(TRAIN, TOKENIZER, MAX_LENGTH)\n",
    "dev_dataset = preprocessing(DEV, TOKENIZER, MAX_LENGTH)\n",
    "test_dataset = preprocessing(TEST, TOKENIZER, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66414f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/cvqikmwd?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x148d2c1c75b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/joemenke/.local/lib/python3.9/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 38:40, Epoch 24/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Igt p</th>\n",
       "      <th>Igt r</th>\n",
       "      <th>Igt f1</th>\n",
       "      <th>Ifg Ada p</th>\n",
       "      <th>Ifg Ada r</th>\n",
       "      <th>Ifg Ada f1</th>\n",
       "      <th>Ifg Who p</th>\n",
       "      <th>Ifg Who r</th>\n",
       "      <th>Ifg Who f1</th>\n",
       "      <th>Hba1c Ada p</th>\n",
       "      <th>Hba1c Ada r</th>\n",
       "      <th>Hba1c Ada f1</th>\n",
       "      <th>Hba1c Iec p</th>\n",
       "      <th>Hba1c Iec r</th>\n",
       "      <th>Hba1c Iec f1</th>\n",
       "      <th>Micro f1</th>\n",
       "      <th>Macro f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.570046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.561900</td>\n",
       "      <td>0.550980</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.422297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.522499</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.347194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.441600</td>\n",
       "      <td>0.511808</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.435931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.524694</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.434545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.344300</td>\n",
       "      <td>0.522961</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.493871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.509225</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.488312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.508111</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.545886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.519682</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.542840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.509930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.519140</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.516566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.534861</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.507820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.521534</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.521622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.531369</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.511947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "bigbird_model = train_huggingface_model(\n",
    "    OUTPUT_DIR,\n",
    "    MODEL_NAME,\n",
    "    TOKENIZER,\n",
    "    train_dataset, \n",
    "    dev_dataset, \n",
    "    NUM_LABELS, \n",
    "    NUM_EPOCHS,\n",
    "    LEARNING_RATE,\n",
    "    WEIGHT_DECAY,\n",
    "    EARLY_STOP_VAR, \n",
    "    GRAD_ACCUM_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "114eaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbird_model.save_model(\"final_models/multilabel_bigbird_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fa2c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1152033/2138710282.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  predictions = np.array(bigbird_model.predict(test_dataset))\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(bigbird_model.predict(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f71f15d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5345389246940613,\n",
       " 'test_IGT P': 0.5151515151515151,\n",
       " 'test_IGT R': 0.8095238095238095,\n",
       " 'test_IGT F1': 0.6296296296296297,\n",
       " 'test_IFG_ADA P': 0.5789473684210527,\n",
       " 'test_IFG_ADA R': 0.4583333333333333,\n",
       " 'test_IFG_ADA F1': 0.5116279069767442,\n",
       " 'test_IFG_WHO P': 0.5,\n",
       " 'test_IFG_WHO R': 0.6842105263157895,\n",
       " 'test_IFG_WHO F1': 0.5777777777777778,\n",
       " 'test_HbA1c_ADA P': 1.0,\n",
       " 'test_HbA1c_ADA R': 0.7,\n",
       " 'test_HbA1c_ADA F1': 0.8235294117647058,\n",
       " 'test_HbA1c_IEC P': 0.0,\n",
       " 'test_HbA1c_IEC R': 0.0,\n",
       " 'test_HbA1c_IEC F1': 0.0,\n",
       " 'test_micro F1': 0.5925925925925926,\n",
       " 'test_macro F1': 0.5085129452297716,\n",
       " 'test_runtime': 10.5316,\n",
       " 'test_samples_per_second': 4.178,\n",
       " 'test_steps_per_second': 4.178}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad7345",
   "metadata": {},
   "source": [
    "### BioLinkBERT-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81927939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "STEPS = 25 # change to 50\n",
    "NUM_LABELS = 5\n",
    "MODEL_NAME = \"michiyasunaga/BioLinkBERT-large\"\n",
    "OUTPUT_DIR = \"multilabel_biolinkbert_large\"\n",
    "MAX_LENGTH = 512\n",
    "EARLY_STOP_VAR = 3\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.001\n",
    "NUM_EPOCHS = 25\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "464e37ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cvqikmwd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/HbA1c_ADA F1</td><td>▁▁▁▄▆▅▇████████</td></tr><tr><td>eval/HbA1c_ADA P</td><td>▁▁▁██▆▆▇▇▇▇▇▇▇▇</td></tr><tr><td>eval/HbA1c_ADA R</td><td>▁▁▁▃▅▅▆████████</td></tr><tr><td>eval/HbA1c_IEC F1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/HbA1c_IEC P</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/HbA1c_IEC R</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/IFG_ADA F1</td><td>████▁▆▃▅▄▂▂▂▃▂▂</td></tr><tr><td>eval/IFG_ADA P</td><td>████▁▆▃▆▄▃▄▇▆▇▇</td></tr><tr><td>eval/IFG_ADA R</td><td>████▁▅▃▅▄▂▂▁▂▁▁</td></tr><tr><td>eval/IFG_WHO F1</td><td>▁█▇▆▇█▇██▇██▇██</td></tr><tr><td>eval/IFG_WHO P</td><td>▁▆██▆▆▆▇▆▆▇▆▆▆▆</td></tr><tr><td>eval/IFG_WHO R</td><td>▁█▅▄▆▇▆▆▇▆▆▆▆▆▆</td></tr><tr><td>eval/IGT F1</td><td>▁▇▅▇▇██████████</td></tr><tr><td>eval/IGT P</td><td>▁▆▇█▆▆▇▇▇▇▆▆▇▆▆</td></tr><tr><td>eval/IGT R</td><td>▁█▃▅▆▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>eval/loss</td><td>█▆▃▁▃▃▁▁▂▃▂▄▃▄▄</td></tr><tr><td>eval/macro F1</td><td>▁▆▅▆▆▇▇██▇▇▇█▇▇</td></tr><tr><td>eval/micro F1</td><td>▁█▅▇▅█▆██▇▇▇▇▇▇</td></tr><tr><td>eval/runtime</td><td>█▂▂▂▃▂▃▁▃▁▃▁▃▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▇▇▅▇▆█▆█▆█▆█▇</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▇▇▅▇▆█▆█▆█▆█▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▆▅▅▄▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>██▇▆▅▄▃▃▂▂▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/HbA1c_ADA F1</td><td>0.72727</td></tr><tr><td>eval/HbA1c_ADA P</td><td>0.8</td></tr><tr><td>eval/HbA1c_ADA R</td><td>0.66667</td></tr><tr><td>eval/HbA1c_IEC F1</td><td>0.0</td></tr><tr><td>eval/HbA1c_IEC P</td><td>0.0</td></tr><tr><td>eval/HbA1c_IEC R</td><td>0.0</td></tr><tr><td>eval/IFG_ADA F1</td><td>0.44444</td></tr><tr><td>eval/IFG_ADA P</td><td>0.54545</td></tr><tr><td>eval/IFG_ADA R</td><td>0.375</td></tr><tr><td>eval/IFG_WHO F1</td><td>0.64516</td></tr><tr><td>eval/IFG_WHO P</td><td>0.55556</td></tr><tr><td>eval/IFG_WHO R</td><td>0.76923</td></tr><tr><td>eval/IGT F1</td><td>0.74286</td></tr><tr><td>eval/IGT P</td><td>0.61905</td></tr><tr><td>eval/IGT R</td><td>0.92857</td></tr><tr><td>eval/loss</td><td>0.53137</td></tr><tr><td>eval/macro F1</td><td>0.51195</td></tr><tr><td>eval/micro F1</td><td>0.62264</td></tr><tr><td>eval/runtime</td><td>6.7229</td></tr><tr><td>eval/samples_per_second</td><td>4.165</td></tr><tr><td>eval/steps_per_second</td><td>4.165</td></tr><tr><td>train/epoch</td><td>24.14</td></tr><tr><td>train/global_step</td><td>350</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1496</td></tr><tr><td>train/total_flos</td><td>6530813712746400.0</td></tr><tr><td>train/train_loss</td><td>0.31603</td></tr><tr><td>train/train_runtime</td><td>2364.4331</td></tr><tr><td>train/train_samples_per_second</td><td>0.613</td></tr><tr><td>train/train_steps_per_second</td><td>0.148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-lake-70</strong> at: <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/cvqikmwd' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/cvqikmwd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230522_182531-cvqikmwd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cvqikmwd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce09f85ad3347728c08bc1c0e9451f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668337226534883, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joemenke/Final_Project/wandb/run-20230522_192536-np5y5puv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/np5y5puv' target=\"_blank\">rare-glitter-71</a></strong> to <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/np5y5puv' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/np5y5puv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/np5y5puv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x148c601afc10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Prediabetes Classification\",\n",
    "           config={\n",
    "               \"model\": MODEL_NAME,\n",
    "               \"max_length\": MAX_LENGTH,\n",
    "               \"epochs\": NUM_EPOCHS,\n",
    "               \"learning_rate\": LEARNING_RATE,\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66cb5898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN, TEST = stratify_multilabel_text(merged_df, test_size=0.33) # train/test split -> 77/33\n",
    "TRAIN, DEV = stratify_multilabel_text(TRAIN, test_size=0.33) # train/dev split -> 77/33\n",
    "\n",
    "train_dataset = preprocessing(TRAIN, TOKENIZER, MAX_LENGTH)\n",
    "dev_dataset = preprocessing(DEV, TOKENIZER, MAX_LENGTH)\n",
    "test_dataset = preprocessing(TEST, TOKENIZER, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a689f3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/np5y5puv?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x148c60157cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at michiyasunaga/BioLinkBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/joemenke/.local/lib/python3.9/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 04:18, Epoch 24/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Igt p</th>\n",
       "      <th>Igt r</th>\n",
       "      <th>Igt f1</th>\n",
       "      <th>Ifg Ada p</th>\n",
       "      <th>Ifg Ada r</th>\n",
       "      <th>Ifg Ada f1</th>\n",
       "      <th>Ifg Who p</th>\n",
       "      <th>Ifg Who r</th>\n",
       "      <th>Ifg Who f1</th>\n",
       "      <th>Hba1c Ada p</th>\n",
       "      <th>Hba1c Ada r</th>\n",
       "      <th>Hba1c Ada f1</th>\n",
       "      <th>Hba1c Iec p</th>\n",
       "      <th>Hba1c Iec r</th>\n",
       "      <th>Hba1c Iec f1</th>\n",
       "      <th>Micro f1</th>\n",
       "      <th>Macro f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.607800</td>\n",
       "      <td>0.560381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.241944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.527100</td>\n",
       "      <td>0.544645</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.192381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.514144</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.417116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>0.513314</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.443123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.271800</td>\n",
       "      <td>0.506632</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.451010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.202300</td>\n",
       "      <td>0.516568</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.412524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.553903</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672269</td>\n",
       "      <td>0.481822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.551696</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.551265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.553324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.551208</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700855</td>\n",
       "      <td>0.582061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.579849</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.578581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.566622</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.583590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.564459</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.592426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.570374</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.583559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "biolink_model = train_huggingface_model(\n",
    "    OUTPUT_DIR,\n",
    "    MODEL_NAME,\n",
    "    TOKENIZER,\n",
    "    train_dataset, \n",
    "    dev_dataset, \n",
    "    NUM_LABELS, \n",
    "    NUM_EPOCHS,\n",
    "    LEARNING_RATE,\n",
    "    WEIGHT_DECAY,\n",
    "    EARLY_STOP_VAR, \n",
    "    GRAD_ACCUM_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80379c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "biolink_model.save_model(\"final_models/multilabel_biolink_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb29fa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1152033/4168129558.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  predictions = np.array(biolink_model.predict(test_dataset))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5004033446311951,\n",
       " 'test_IGT P': 0.6129032258064516,\n",
       " 'test_IGT R': 0.9047619047619048,\n",
       " 'test_IGT F1': 0.7307692307692307,\n",
       " 'test_IFG_ADA P': 0.6666666666666666,\n",
       " 'test_IFG_ADA R': 0.8333333333333334,\n",
       " 'test_IFG_ADA F1': 0.7407407407407408,\n",
       " 'test_IFG_WHO P': 0.6521739130434783,\n",
       " 'test_IFG_WHO R': 0.7894736842105263,\n",
       " 'test_IFG_WHO F1': 0.7142857142857143,\n",
       " 'test_HbA1c_ADA P': 1.0,\n",
       " 'test_HbA1c_ADA R': 0.7,\n",
       " 'test_HbA1c_ADA F1': 0.8235294117647058,\n",
       " 'test_HbA1c_IEC P': 0.0,\n",
       " 'test_HbA1c_IEC R': 0.0,\n",
       " 'test_HbA1c_IEC F1': 0.0,\n",
       " 'test_micro F1': 0.7261904761904762,\n",
       " 'test_macro F1': 0.6018650195120783,\n",
       " 'test_runtime': 1.9989,\n",
       " 'test_samples_per_second': 22.012,\n",
       " 'test_steps_per_second': 22.012}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(biolink_model.predict(test_dataset))\n",
    "predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a0c009",
   "metadata": {},
   "source": [
    "### BioGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6255302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "NUM_LABELS = 5\n",
    "MODEL_NAME = \"microsoft/biogpt\"\n",
    "MAX_LENGTH = 1024 # default; longest sequence currently = 2554 -> works w/ gradient checkpointing\n",
    "NUM_EPOCHS = 25\n",
    "OUTPUT_DIR = \"final_models/output_biogpt/state_dict_best_model.pt\" # include a directory and a file\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-5\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0436a993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joemenke/Final_Project/wandb/run-20230522_194327-a35jq48y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/a35jq48y' target=\"_blank\">vibrant-grass-73</a></strong> to <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/a35jq48y' target=\"_blank\">https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/a35jq48y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/a35jq48y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1522443e0f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Prediabetes Classification\",\n",
    "           config={\n",
    "               \"model\": MODEL_NAME,\n",
    "               \"max_length\": MAX_LENGTH,\n",
    "               \"epochs\": NUM_EPOCHS,\n",
    "               \"learning_rate\": LEARNING_RATE,\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e369ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: (58, 2); Dev size: (28, 2); Testing size: (44, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN, TEST = stratify_multilabel_text(merged_df, test_size=0.33) # train/test split -> 77/33\n",
    "TRAIN, DEV = stratify_multilabel_text(TRAIN, test_size=0.33) # train/dev split -> 77/33\n",
    "print(f\"Training size: {TRAIN.shape}; Dev size: {DEV.shape}; Testing size: {TEST.shape}\")\n",
    "\n",
    "train_dataset = preprocessing(TRAIN, TOKENIZER, MAX_LENGTH)\n",
    "dev_dataset = preprocessing(DEV, TOKENIZER, MAX_LENGTH)\n",
    "test_dataset = preprocessing(TEST, TOKENIZER, MAX_LENGTH)\n",
    "\n",
    "train_params = {'batch_size': BATCH_SIZE, 'shuffle': SHUFFLE, 'num_workers': NUM_WORKERS}\n",
    "dev_params = {'batch_size': BATCH_SIZE, 'shuffle': SHUFFLE, 'num_workers': NUM_WORKERS}\n",
    "test_params = {'batch_size': BATCH_SIZE, 'shuffle': SHUFFLE, 'num_workers': NUM_WORKERS}\n",
    "\n",
    "TRAIN_LOADER = DataLoader(train_dataset, **train_params)\n",
    "DEV_LOADER = DataLoader(dev_dataset, **dev_params)\n",
    "TEST_LOADER = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643f2af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/biogpt were not used when initializing BioGptForSequenceClassification: ['output_projection.weight']\n",
      "- This IS expected if you are initializing BioGptForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BioGptForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BioGptForSequenceClassification were not initialized from the model checkpoint at microsoft/biogpt and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL = BioGptForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    max_position_embeddings=MAX_LENGTH,\n",
    ").to(DEVICE)\n",
    "\n",
    "MODEL.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f680a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biogpt_save_model(model, epoch, optimizer, out_file):\n",
    "    out_dir = \"\".join(out_file.rsplit('/', 1)[:-1])\n",
    "    print(f\"...Saving model\")\n",
    "    if os.path.exists(out_dir):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, out_file)\n",
    "    else:\n",
    "        os.makedirs(out_dir)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, out_file)\n",
    "\n",
    "def biogpt_validate(device, model, test_dataloader):\n",
    "    all_preds = torch.tensor((), device='cpu')\n",
    "    pred_labels = torch.tensor((), device='cpu')\n",
    "\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        text = batch.pop('text')\n",
    "        batch['labels'] = torch.transpose(torch.stack(batch['labels'], dim=0), 0, 1)\n",
    "        labels = batch.pop('labels').type(torch.LongTensor)\n",
    "        batch['input_ids'] = torch.transpose(torch.stack(batch['input_ids'], dim=0), 0, 1)\n",
    "        batch['attention_mask'] = torch.transpose(torch.stack(batch['attention_mask'], dim=0), 0, 1)\n",
    "        for key, value in batch.items():\n",
    "            batch[key] = batch[key].to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**batch).logits\n",
    "\n",
    "        predictions = torch.sigmoid(logits) > 0.5\n",
    "        predictions = predictions.type(torch.LongTensor)\n",
    "        all_preds = torch.cat((all_preds, predictions))\n",
    "        pred_labels = torch.cat((pred_labels, labels))\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    return all_preds, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f2f902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biogpt_train(device, model, output_dir, training_loader, testing_loader, num_labels, num_epochs, learn_rate):\n",
    "    optimizer = AdamW(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    num_training_steps = num_epochs * len(training_loader)\n",
    "    \n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    best_f1_score_macro = 0\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for idx, batch in enumerate(training_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch.pop('text')\n",
    "            batch['labels'] = torch.transpose(torch.stack(batch['labels'], dim=0), 0, 1)\n",
    "            labels = batch.pop('labels').to(torch.float).to(device)\n",
    "            batch['input_ids'] = torch.transpose(torch.stack(batch['input_ids'], dim=0), 0, 1)\n",
    "            batch['attention_mask'] = torch.transpose(torch.stack(batch['attention_mask'], dim=0), 0, 1)\n",
    "            for key, value in batch.items():\n",
    "                batch[key] = batch[key].to(device)\n",
    "            \n",
    "            loss = model(**batch, labels=labels).loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Validation check every 25 instances\n",
    "            if (idx % 25 == 0):\n",
    "                outputs, targets = biogpt_validate(device, model, testing_loader)\n",
    "\n",
    "                precision_macro = metrics.precision_score(targets, outputs, average='macro', zero_division=0)\n",
    "                recall_macro = metrics.recall_score(targets, outputs, average='macro')\n",
    "                f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "                f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "                \n",
    "                all_labels = ['IGT', 'IFG_ADA', 'IFG_WHO', 'HbA1c_ADA', 'HbA1c_IEC']\n",
    "                clf_dict = metrics.classification_report(targets, outputs, target_names=all_labels,\n",
    "                                                         zero_division=0, output_dict=True)\n",
    "                \n",
    "                wandb.log({\n",
    "                    \"loss\": loss.item(), \n",
    "                    \"Precision\": precision_macro,\n",
    "                    \"Recall\": recall_macro,\n",
    "                    \"Micro F1\": f1_score_micro,\n",
    "                    \"Macro F1\": f1_score_macro,\n",
    "                })\n",
    "                \n",
    "                print(f\"Step: {epoch}, {idx}, Loss: {loss.item()}\")\n",
    "                print(f\"Precision (Macro): {precision_macro}, Recall (Macro): {recall_macro}\")\n",
    "                print(f\"F1 Score (Micro): {f1_score_micro}, F1 Score (Macro): {f1_score_macro}\")\n",
    "                print(clf_dict)\n",
    "                print()\n",
    "                if f1_score_macro > best_f1_score_macro:\n",
    "                    biogpt_save_model(model, epoch, optimizer, output_dir)\n",
    "                    best_f1_score_macro = f1_score_macro\n",
    "            \n",
    "            progress_bar.update(1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88f467a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/nlp4health/Prediabetes%20Classification/runs/a35jq48y?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x152242f19100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1450 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, 0, Loss: 0.9119990468025208\n",
      "Precision (Macro): 0.36468864468864465, Recall (Macro): 0.46973443223443223\n",
      "F1 Score (Micro): 0.45, F1 Score (Macro): 0.3745182353878006\n",
      "{'IGT': {'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1-score': 0.6153846153846153, 'support': 14}, 'IFG_ADA': {'precision': 0.42857142857142855, 'recall': 0.1875, 'f1-score': 0.26086956521739124, 'support': 16}, 'IFG_WHO': {'precision': 0.46153846153846156, 'recall': 0.9230769230769231, 'f1-score': 0.6153846153846155, 'support': 13}, 'HbA1c_ADA': {'precision': 0.26666666666666666, 'recall': 0.6666666666666666, 'f1-score': 0.3809523809523809, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.391304347826087, 'recall': 0.5294117647058824, 'f1-score': 0.45, 'support': 51}, 'macro avg': {'precision': 0.36468864468864465, 'recall': 0.46973443223443223, 'f1-score': 0.3745182353878006, 'support': 51}, 'weighted avg': {'precision': 0.4664799253034547, 'recall': 0.5294117647058824, 'f1-score': 0.45245121459955223, 'support': 51}, 'samples avg': {'precision': 0.38095238095238093, 'recall': 0.5005952380952381, 'f1-score': 0.4106292517006803, 'support': 51}}\n",
      "\n",
      "...Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 26/1450 [00:31<26:52,  1.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, 25, Loss: 1.150293231010437\n",
      "Precision (Macro): 0.36444444444444446, Recall (Macro): 0.29079670329670326\n",
      "F1 Score (Micro): 0.48888888888888893, F1 Score (Macro): 0.28620155038759687\n",
      "{'IGT': {'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1-score': 0.4, 'support': 14}, 'IFG_ADA': {'precision': 0.5555555555555556, 'recall': 0.9375, 'f1-score': 0.6976744186046512, 'support': 16}, 'IFG_WHO': {'precision': 0.6, 'recall': 0.23076923076923078, 'f1-score': 0.33333333333333337, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5641025641025641, 'recall': 0.43137254901960786, 'f1-score': 0.48888888888888893, 'support': 51}, 'macro avg': {'precision': 0.36444444444444446, 'recall': 0.29079670329670326, 'f1-score': 0.28620155038759687, 'support': 51}, 'weighted avg': {'precision': 0.510239651416122, 'recall': 0.43137254901960786, 'f1-score': 0.4136494908040736, 'support': 51}, 'samples avg': {'precision': 0.5773809523809523, 'recall': 0.4577380952380952, 'f1-score': 0.47636054421768703, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 51/1450 [00:43<26:13,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, 50, Loss: 0.6667962074279785\n",
      "Precision (Macro): 0.3563636363636363, Recall (Macro): 0.30480769230769234\n",
      "F1 Score (Micro): 0.48888888888888893, F1 Score (Macro): 0.3281290322580645\n",
      "{'IGT': {'precision': 0.6363636363636364, 'recall': 0.5, 'f1-score': 0.56, 'support': 14}, 'IFG_ADA': {'precision': 0.6, 'recall': 0.5625, 'f1-score': 0.5806451612903225, 'support': 16}, 'IFG_WHO': {'precision': 0.5454545454545454, 'recall': 0.46153846153846156, 'f1-score': 0.4999999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5641025641025641, 'recall': 0.43137254901960786, 'f1-score': 0.48888888888888893, 'support': 51}, 'macro avg': {'precision': 0.3563636363636363, 'recall': 0.30480769230769234, 'f1-score': 0.3281290322580645, 'support': 51}, 'weighted avg': {'precision': 0.5019607843137255, 'recall': 0.43137254901960786, 'f1-score': 0.4633396584440227, 'support': 51}, 'samples avg': {'precision': 0.4107142857142857, 'recall': 0.39345238095238094, 'f1-score': 0.36488095238095236, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 59/1450 [00:49<27:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, 0, Loss: 0.18572452664375305\n",
      "Precision (Macro): 0.36444444444444446, Recall (Macro): 0.3787087912087912\n",
      "F1 Score (Micro): 0.5656565656565657, F1 Score (Macro): 0.3603274774006481\n",
      "{'IGT': {'precision': 0.6666666666666666, 'recall': 0.5714285714285714, 'f1-score': 0.6153846153846153, 'support': 14}, 'IFG_ADA': {'precision': 0.6, 'recall': 0.9375, 'f1-score': 0.7317073170731707, 'support': 16}, 'IFG_WHO': {'precision': 0.5555555555555556, 'recall': 0.38461538461538464, 'f1-score': 0.4545454545454546, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5833333333333334, 'recall': 0.5490196078431373, 'f1-score': 0.5656565656565657, 'support': 51}, 'macro avg': {'precision': 0.36444444444444446, 'recall': 0.3787087912087912, 'f1-score': 0.3603274774006481, 'support': 51}, 'weighted avg': {'precision': 0.5128540305010892, 'recall': 0.5490196078431373, 'f1-score': 0.5143488744636521, 'support': 51}, 'samples avg': {'precision': 0.5654761904761905, 'recall': 0.5738095238095238, 'f1-score': 0.5301020408163265, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 84/1450 [01:00<25:47,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, 25, Loss: 0.530479907989502\n",
      "Precision (Macro): 0.33776223776223774, Recall (Macro): 0.29409340659340655\n",
      "F1 Score (Micro): 0.4666666666666667, F1 Score (Macro): 0.31364102564102564\n",
      "{'IGT': {'precision': 0.7272727272727273, 'recall': 0.5714285714285714, 'f1-score': 0.64, 'support': 14}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.4375, 'f1-score': 0.4666666666666667, 'support': 16}, 'IFG_WHO': {'precision': 0.46153846153846156, 'recall': 0.46153846153846156, 'f1-score': 0.46153846153846156, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5384615384615384, 'recall': 0.4117647058823529, 'f1-score': 0.4666666666666667, 'support': 51}, 'macro avg': {'precision': 0.33776223776223774, 'recall': 0.29409340659340655, 'f1-score': 0.31364102564102564, 'support': 51}, 'weighted avg': {'precision': 0.4741532976827094, 'recall': 0.4117647058823529, 'f1-score': 0.4397385620915033, 'support': 51}, 'samples avg': {'precision': 0.380952380952381, 'recall': 0.3773809523809524, 'f1-score': 0.35153061224489796, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 109/1450 [01:12<25:14,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, 50, Loss: 0.5608019828796387\n",
      "Precision (Macro): 0.36, Recall (Macro): 0.2061813186813187\n",
      "F1 Score (Micro): 0.37500000000000006, F1 Score (Macro): 0.2549494949494949\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.2857142857142857, 'f1-score': 0.36363636363636365, 'support': 14}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.4375, 'f1-score': 0.4666666666666667, 'support': 16}, 'IFG_WHO': {'precision': 0.8, 'recall': 0.3076923076923077, 'f1-score': 0.4444444444444444, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5172413793103449, 'recall': 0.29411764705882354, 'f1-score': 0.37500000000000006, 'support': 51}, 'macro avg': {'precision': 0.36, 'recall': 0.2061813186813187, 'f1-score': 0.2549494949494949, 'support': 51}, 'weighted avg': {'precision': 0.49803921568627446, 'recall': 0.29411764705882354, 'f1-score': 0.35951673598732425, 'support': 51}, 'samples avg': {'precision': 0.34523809523809523, 'recall': 0.26011904761904764, 'f1-score': 0.2738095238095238, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 117/1450 [01:18<26:26,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2, 0, Loss: 0.07065486162900925\n",
      "Precision (Macro): 0.372, Recall (Macro): 0.2793956043956044\n",
      "F1 Score (Micro): 0.4719101123595506, F1 Score (Macro): 0.2854742547425474\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.21428571428571427, 'f1-score': 0.3, 'support': 14}, 'IFG_ADA': {'precision': 0.56, 'recall': 0.875, 'f1-score': 0.6829268292682927, 'support': 16}, 'IFG_WHO': {'precision': 0.8, 'recall': 0.3076923076923077, 'f1-score': 0.4444444444444444, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5526315789473685, 'recall': 0.4117647058823529, 'f1-score': 0.4719101123595506, 'support': 51}, 'macro avg': {'precision': 0.372, 'recall': 0.2793956043956044, 'f1-score': 0.2854742547425474, 'support': 51}, 'weighted avg': {'precision': 0.5168627450980392, 'recall': 0.4117647058823529, 'f1-score': 0.4098942558053032, 'support': 51}, 'samples avg': {'precision': 0.5416666666666666, 'recall': 0.4386904761904762, 'f1-score': 0.45833333333333337, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 142/1450 [01:30<24:37,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2, 25, Loss: 0.7244458198547363\n",
      "Precision (Macro): 0.2761084529505582, Recall (Macro): 0.35769230769230764\n",
      "F1 Score (Micro): 0.47706422018348627, F1 Score (Macro): 0.31116427432216903\n",
      "{'IGT': {'precision': 0.3684210526315789, 'recall': 0.5, 'f1-score': 0.4242424242424242, 'support': 14}, 'IFG_ADA': {'precision': 0.5454545454545454, 'recall': 0.75, 'f1-score': 0.631578947368421, 'support': 16}, 'IFG_WHO': {'precision': 0.4666666666666667, 'recall': 0.5384615384615384, 'f1-score': 0.5, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.4482758620689655, 'recall': 0.5098039215686274, 'f1-score': 0.47706422018348627, 'support': 51}, 'macro avg': {'precision': 0.2761084529505582, 'recall': 0.35769230769230764, 'f1-score': 0.31116427432216903, 'support': 51}, 'weighted avg': {'precision': 0.39121243393689215, 'recall': 0.5098039215686274, 'f1-score': 0.44205209994683675, 'support': 51}, 'samples avg': {'precision': 0.46428571428571436, 'recall': 0.5708333333333334, 'f1-score': 0.4715986394557823, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 167/1450 [01:41<24:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2, 50, Loss: 0.406205415725708\n",
      "Precision (Macro): 0.32777777777777783, Recall (Macro): 0.22692307692307692\n",
      "F1 Score (Micro): 0.3855421686746988, F1 Score (Macro): 0.26573913043478264\n",
      "{'IGT': {'precision': 0.7777777777777778, 'recall': 0.5, 'f1-score': 0.6086956521739131, 'support': 14}, 'IFG_ADA': {'precision': 0.4444444444444444, 'recall': 0.25, 'f1-score': 0.32, 'support': 16}, 'IFG_WHO': {'precision': 0.4166666666666667, 'recall': 0.38461538461538464, 'f1-score': 0.4, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5, 'recall': 0.3137254901960784, 'f1-score': 0.3855421686746988, 'support': 51}, 'macro avg': {'precision': 0.32777777777777783, 'recall': 0.22692307692307692, 'f1-score': 0.26573913043478264, 'support': 51}, 'weighted avg': {'precision': 0.45915032679738566, 'recall': 0.3137254901960784, 'f1-score': 0.3694458653026428, 'support': 51}, 'samples avg': {'precision': 0.35714285714285715, 'recall': 0.2958333333333333, 'f1-score': 0.28809523809523807, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 175/1450 [01:47<24:58,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3, 0, Loss: 0.40888839960098267\n",
      "Precision (Macro): 0.3282828282828283, Recall (Macro): 0.22692307692307692\n",
      "F1 Score (Micro): 0.3855421686746988, F1 Score (Macro): 0.26795491143317235\n",
      "{'IGT': {'precision': 0.7777777777777778, 'recall': 0.5, 'f1-score': 0.6086956521739131, 'support': 14}, 'IFG_ADA': {'precision': 0.36363636363636365, 'recall': 0.25, 'f1-score': 0.2962962962962963, 'support': 16}, 'IFG_WHO': {'precision': 0.5, 'recall': 0.38461538461538464, 'f1-score': 0.4347826086956522, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5, 'recall': 0.3137254901960784, 'f1-score': 0.3855421686746988, 'support': 51}, 'macro avg': {'precision': 0.3282828282828283, 'recall': 0.22692307692307692, 'f1-score': 0.26795491143317235, 'support': 51}, 'weighted avg': {'precision': 0.4550406020994256, 'recall': 0.3137254901960784, 'f1-score': 0.37087556439645103, 'support': 51}, 'samples avg': {'precision': 0.36309523809523814, 'recall': 0.29583333333333334, 'f1-score': 0.29404761904761906, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 200/1450 [01:59<23:33,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3, 25, Loss: 0.357820063829422\n",
      "Precision (Macro): 0.35194805194805195, Recall (Macro): 0.26263736263736265\n",
      "F1 Score (Micro): 0.4418604651162791, F1 Score (Macro): 0.296\n",
      "{'IGT': {'precision': 0.5454545454545454, 'recall': 0.42857142857142855, 'f1-score': 0.4799999999999999, 'support': 14}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 16}, 'IFG_WHO': {'precision': 0.7142857142857143, 'recall': 0.38461538461538464, 'f1-score': 0.5, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5428571428571428, 'recall': 0.37254901960784315, 'f1-score': 0.4418604651162791, 'support': 51}, 'macro avg': {'precision': 0.35194805194805195, 'recall': 0.26263736263736265, 'f1-score': 0.296, 'support': 51}, 'weighted avg': {'precision': 0.48866819455054755, 'recall': 0.37254901960784315, 'f1-score': 0.416078431372549, 'support': 51}, 'samples avg': {'precision': 0.4345238095238095, 'recall': 0.35059523809523807, 'f1-score': 0.357312925170068, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 225/1450 [02:11<23:07,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3, 50, Loss: 0.027957474812865257\n",
      "Precision (Macro): 0.326025641025641, Recall (Macro): 0.2666208791208791\n",
      "F1 Score (Micro): 0.4318181818181818, F1 Score (Macro): 0.2889239792465599\n",
      "{'IGT': {'precision': 0.625, 'recall': 0.35714285714285715, 'f1-score': 0.45454545454545453, 'support': 14}, 'IFG_ADA': {'precision': 0.4666666666666667, 'recall': 0.4375, 'f1-score': 0.45161290322580644, 'support': 16}, 'IFG_WHO': {'precision': 0.5384615384615384, 'recall': 0.5384615384615384, 'f1-score': 0.5384615384615384, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5135135135135135, 'recall': 0.37254901960784315, 'f1-score': 0.4318181818181818, 'support': 51}, 'macro avg': {'precision': 0.326025641025641, 'recall': 0.2666208791208791, 'f1-score': 0.2889239792465599, 'support': 51}, 'weighted avg': {'precision': 0.4552287581699347, 'recall': 0.37254901960784315, 'f1-score': 0.4037145650048876, 'support': 51}, 'samples avg': {'precision': 0.42857142857142866, 'recall': 0.35059523809523807, 'f1-score': 0.35374149659863946, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 233/1450 [02:16<23:53,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4, 0, Loss: 0.21041451394557953\n",
      "Precision (Macro): 0.37315508021390376, Recall (Macro): 0.32019230769230766\n",
      "F1 Score (Micro): 0.5111111111111111, F1 Score (Macro): 0.34242424242424246\n",
      "{'IGT': {'precision': 0.7, 'recall': 0.5, 'f1-score': 0.5833333333333334, 'support': 14}, 'IFG_ADA': {'precision': 0.5294117647058824, 'recall': 0.5625, 'f1-score': 0.5454545454545455, 'support': 16}, 'IFG_WHO': {'precision': 0.6363636363636364, 'recall': 0.5384615384615384, 'f1-score': 0.5833333333333334, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5897435897435898, 'recall': 0.45098039215686275, 'f1-score': 0.5111111111111111, 'support': 51}, 'macro avg': {'precision': 0.37315508021390376, 'recall': 0.32019230769230766, 'f1-score': 0.34242424242424246, 'support': 51}, 'weighted avg': {'precision': 0.5204571668239488, 'recall': 0.45098039215686275, 'f1-score': 0.47994652406417126, 'support': 51}, 'samples avg': {'precision': 0.5416666666666666, 'recall': 0.4577380952380952, 'f1-score': 0.4585034013605442, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 258/1450 [02:28<22:29,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4, 25, Loss: 0.05759849771857262\n",
      "Precision (Macro): 0.3388888888888889, Recall (Macro): 0.2837912087912088\n",
      "F1 Score (Micro): 0.4444444444444445, F1 Score (Macro): 0.29803100125680776\n",
      "{'IGT': {'precision': 0.75, 'recall': 0.42857142857142855, 'f1-score': 0.5454545454545454, 'support': 14}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.375, 'f1-score': 0.42857142857142855, 'support': 16}, 'IFG_WHO': {'precision': 0.4444444444444444, 'recall': 0.6153846153846154, 'f1-score': 0.5161290322580646, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5128205128205128, 'recall': 0.39215686274509803, 'f1-score': 0.4444444444444445, 'support': 51}, 'macro avg': {'precision': 0.3388888888888889, 'recall': 0.2837912087912088, 'f1-score': 0.29803100125680776, 'support': 51}, 'weighted avg': {'precision': 0.4760348583877996, 'recall': 0.39215686274509803, 'f1-score': 0.41574870417375165, 'support': 51}, 'samples avg': {'precision': 0.4107142857142857, 'recall': 0.3684523809523809, 'f1-score': 0.3537414965986394, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 283/1450 [02:40<23:07,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4, 50, Loss: 0.3338630795478821\n",
      "Precision (Macro): 0.3130909090909091, Recall (Macro): 0.40302197802197803\n",
      "F1 Score (Micro): 0.5370370370370371, F1 Score (Macro): 0.34444444444444444\n",
      "{'IGT': {'precision': 0.52, 'recall': 0.9285714285714286, 'f1-score': 0.6666666666666666, 'support': 14}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.625, 'f1-score': 0.5555555555555556, 'support': 16}, 'IFG_WHO': {'precision': 0.5454545454545454, 'recall': 0.46153846153846156, 'f1-score': 0.4999999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5087719298245614, 'recall': 0.5686274509803921, 'f1-score': 0.5370370370370371, 'support': 51}, 'macro avg': {'precision': 0.3130909090909091, 'recall': 0.40302197802197803, 'f1-score': 0.34444444444444444, 'support': 51}, 'weighted avg': {'precision': 0.43864527629233513, 'recall': 0.5686274509803921, 'f1-score': 0.4847494553376906, 'support': 51}, 'samples avg': {'precision': 0.46428571428571425, 'recall': 0.5321428571428571, 'f1-score': 0.46819727891156454, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 291/1450 [02:45<22:49,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5, 0, Loss: 0.45884376764297485\n",
      "Precision (Macro): 0.33055555555555555, Recall (Macro): 0.3505494505494505\n",
      "F1 Score (Micro): 0.5102040816326531, F1 Score (Macro): 0.3394509803921569\n",
      "{'IGT': {'precision': 0.625, 'recall': 0.7142857142857143, 'f1-score': 0.6666666666666666, 'support': 14}, 'IFG_ADA': {'precision': 0.4444444444444444, 'recall': 0.5, 'f1-score': 0.47058823529411764, 'support': 16}, 'IFG_WHO': {'precision': 0.5833333333333334, 'recall': 0.5384615384615384, 'f1-score': 0.5599999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5319148936170213, 'recall': 0.49019607843137253, 'f1-score': 0.5102040816326531, 'support': 51}, 'macro avg': {'precision': 0.33055555555555555, 'recall': 0.3505494505494505, 'f1-score': 0.3394509803921569, 'support': 51}, 'weighted avg': {'precision': 0.45969498910675377, 'recall': 0.49019607843137253, 'f1-score': 0.47338715878508264, 'support': 51}, 'samples avg': {'precision': 0.4642857142857143, 'recall': 0.4666666666666667, 'f1-score': 0.4372448979591837, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 316/1450 [02:57<21:24,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5, 25, Loss: 0.006591461598873138\n",
      "Precision (Macro): 0.3280701754385965, Recall (Macro): 0.2487637362637362\n",
      "F1 Score (Micro): 0.40909090909090917, F1 Score (Macro): 0.2536196700902583\n",
      "{'IGT': {'precision': 0.6666666666666666, 'recall': 0.14285714285714285, 'f1-score': 0.23529411764705882, 'support': 14}, 'IFG_ADA': {'precision': 0.47368421052631576, 'recall': 0.5625, 'f1-score': 0.5142857142857142, 'support': 16}, 'IFG_WHO': {'precision': 0.5, 'recall': 0.5384615384615384, 'f1-score': 0.5185185185185186, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.4864864864864865, 'recall': 0.35294117647058826, 'f1-score': 0.40909090909090917, 'support': 51}, 'macro avg': {'precision': 0.3280701754385965, 'recall': 0.2487637362637362, 'f1-score': 0.2536196700902583, 'support': 51}, 'weighted avg': {'precision': 0.45906432748538006, 'recall': 0.35294117647058826, 'f1-score': 0.35810646698766657, 'support': 51}, 'samples avg': {'precision': 0.4404761904761904, 'recall': 0.3494047619047619, 'f1-score': 0.3571428571428571, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 341/1450 [03:09<20:58,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5, 50, Loss: 0.12637124955654144\n",
      "Precision (Macro): 0.27149999999999996, Recall (Macro): 0.36840659340659343\n",
      "F1 Score (Micro): 0.47706422018348627, F1 Score (Macro): 0.3073044123099741\n",
      "{'IGT': {'precision': 0.52, 'recall': 0.9285714285714286, 'f1-score': 0.6666666666666666, 'support': 14}, 'IFG_ADA': {'precision': 0.4, 'recall': 0.375, 'f1-score': 0.38709677419354843, 'support': 16}, 'IFG_WHO': {'precision': 0.4375, 'recall': 0.5384615384615384, 'f1-score': 0.4827586206896552, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.4482758620689655, 'recall': 0.5098039215686274, 'f1-score': 0.47706422018348627, 'support': 51}, 'macro avg': {'precision': 0.27149999999999996, 'recall': 0.36840659340659343, 'f1-score': 0.3073044123099741, 'support': 51}, 'weighted avg': {'precision': 0.3797549019607843, 'recall': 0.5098039215686274, 'f1-score': 0.427504780184228, 'support': 51}, 'samples avg': {'precision': 0.4404761904761905, 'recall': 0.4714285714285714, 'f1-score': 0.4204081632653061, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 349/1450 [03:15<21:36,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6, 0, Loss: 0.0972609743475914\n",
      "Precision (Macro): 0.29349460608041844, Recall (Macro): 0.33722527472527475\n",
      "F1 Score (Micro): 0.4854368932038835, F1 Score (Macro): 0.30242424242424243\n",
      "{'IGT': {'precision': 0.47368421052631576, 'recall': 0.6428571428571429, 'f1-score': 0.5454545454545454, 'support': 14}, 'IFG_ADA': {'precision': 0.5652173913043478, 'recall': 0.8125, 'f1-score': 0.6666666666666667, 'support': 16}, 'IFG_WHO': {'precision': 0.42857142857142855, 'recall': 0.23076923076923078, 'f1-score': 0.3, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.4807692307692308, 'recall': 0.49019607843137253, 'f1-score': 0.4854368932038835, 'support': 51}, 'macro avg': {'precision': 0.29349460608041844, 'recall': 0.33722527472527475, 'f1-score': 0.30242424242424243, 'support': 51}, 'weighted avg': {'precision': 0.41659776038561874, 'recall': 0.49019607843137253, 'f1-score': 0.4353535353535354, 'support': 51}, 'samples avg': {'precision': 0.4523809523809524, 'recall': 0.5380952380952381, 'f1-score': 0.4465986394557823, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 374/1450 [03:26<20:20,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6, 25, Loss: 0.25768762826919556\n",
      "Precision (Macro): 0.33246753246753247, Recall (Macro): 0.29945054945054944\n",
      "F1 Score (Micro): 0.4731182795698925, F1 Score (Macro): 0.30250626566416033\n",
      "{'IGT': {'precision': 0.5714285714285714, 'recall': 0.2857142857142857, 'f1-score': 0.38095238095238093, 'support': 14}, 'IFG_ADA': {'precision': 0.5454545454545454, 'recall': 0.75, 'f1-score': 0.631578947368421, 'support': 16}, 'IFG_WHO': {'precision': 0.5454545454545454, 'recall': 0.46153846153846156, 'f1-score': 0.4999999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5238095238095238, 'recall': 0.43137254901960786, 'f1-score': 0.4731182795698925, 'support': 51}, 'macro avg': {'precision': 0.33246753246753247, 'recall': 0.29945054945054944, 'f1-score': 0.30250626566416033, 'support': 51}, 'weighted avg': {'precision': 0.4670231729055258, 'recall': 0.43137254901960786, 'f1-score': 0.43016855865153075, 'support': 51}, 'samples avg': {'precision': 0.5119047619047619, 'recall': 0.4505952380952381, 'f1-score': 0.4476190476190475, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 399/1450 [03:38<19:50,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6, 50, Loss: 0.004420569632202387\n",
      "Precision (Macro): 0.3555555555555555, Recall (Macro): 0.25054945054945055\n",
      "F1 Score (Micro): 0.41379310344827586, F1 Score (Macro): 0.27278431372549017\n",
      "{'IGT': {'precision': 0.75, 'recall': 0.21428571428571427, 'f1-score': 0.3333333333333333, 'support': 14}, 'IFG_ADA': {'precision': 0.4444444444444444, 'recall': 0.5, 'f1-score': 0.47058823529411764, 'support': 16}, 'IFG_WHO': {'precision': 0.5833333333333334, 'recall': 0.5384615384615384, 'f1-score': 0.5599999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5, 'recall': 0.35294117647058826, 'f1-score': 0.41379310344827586, 'support': 51}, 'macro avg': {'precision': 0.3555555555555555, 'recall': 0.25054945054945055, 'f1-score': 0.27278431372549017, 'support': 51}, 'weighted avg': {'precision': 0.49400871459694984, 'recall': 0.35294117647058826, 'f1-score': 0.3818838908112265, 'support': 51}, 'samples avg': {'precision': 0.4583333333333333, 'recall': 0.3494047619047619, 'f1-score': 0.375, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 407/1450 [03:44<20:28,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7, 0, Loss: 0.023608503863215446\n",
      "Precision (Macro): 0.3706060606060606, Recall (Macro): 0.22733516483516483\n",
      "F1 Score (Micro): 0.3950617283950617, F1 Score (Macro): 0.27230576441102755\n",
      "{'IGT': {'precision': 0.8, 'recall': 0.2857142857142857, 'f1-score': 0.4210526315789473, 'support': 14}, 'IFG_ADA': {'precision': 0.4166666666666667, 'recall': 0.3125, 'f1-score': 0.35714285714285715, 'support': 16}, 'IFG_WHO': {'precision': 0.6363636363636364, 'recall': 0.5384615384615384, 'f1-score': 0.5833333333333334, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5333333333333333, 'recall': 0.3137254901960784, 'f1-score': 0.3950617283950617, 'support': 51}, 'macro avg': {'precision': 0.3706060606060606, 'recall': 0.22733516483516483, 'f1-score': 0.27230576441102755, 'support': 51}, 'weighted avg': {'precision': 0.5125371360665478, 'recall': 0.3137254901960784, 'f1-score': 0.3763207037200845, 'support': 51}, 'samples avg': {'precision': 0.40476190476190477, 'recall': 0.2958333333333333, 'f1-score': 0.3178571428571429, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 432/1450 [03:56<19:16,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7, 25, Loss: 0.01141520868986845\n",
      "Precision (Macro): 0.36944444444444446, Recall (Macro): 0.320467032967033\n",
      "F1 Score (Micro): 0.5106382978723404, F1 Score (Macro): 0.3146545009458106\n",
      "{'IGT': {'precision': 0.625, 'recall': 0.35714285714285715, 'f1-score': 0.45454545454545453, 'support': 14}, 'IFG_ADA': {'precision': 0.5555555555555556, 'recall': 0.9375, 'f1-score': 0.6976744186046512, 'support': 16}, 'IFG_WHO': {'precision': 0.6666666666666666, 'recall': 0.3076923076923077, 'f1-score': 0.42105263157894735, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5581395348837209, 'recall': 0.47058823529411764, 'f1-score': 0.5106382978723404, 'support': 51}, 'macro avg': {'precision': 0.36944444444444446, 'recall': 0.320467032967033, 'f1-score': 0.3146545009458106, 'support': 51}, 'weighted avg': {'precision': 0.5157952069716776, 'recall': 0.47058823529411764, 'f1-score': 0.45098257395759017, 'support': 51}, 'samples avg': {'precision': 0.5595238095238095, 'recall': 0.5041666666666667, 'f1-score': 0.49523809523809514, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 457/1450 [04:08<18:48,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7, 50, Loss: 0.09930653125047684\n",
      "Precision (Macro): 0.32781217750257996, Recall (Macro): 0.3612637362637362\n",
      "F1 Score (Micro): 0.5199999999999999, F1 Score (Macro): 0.34241474654377885\n",
      "{'IGT': {'precision': 0.5294117647058824, 'recall': 0.6428571428571429, 'f1-score': 0.5806451612903226, 'support': 14}, 'IFG_ADA': {'precision': 0.5263157894736842, 'recall': 0.625, 'f1-score': 0.5714285714285714, 'support': 16}, 'IFG_WHO': {'precision': 0.5833333333333334, 'recall': 0.5384615384615384, 'f1-score': 0.5599999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5306122448979592, 'recall': 0.5098039215686274, 'f1-score': 0.5199999999999999, 'support': 51}, 'macro avg': {'precision': 0.32781217750257996, 'recall': 0.3612637362637362, 'f1-score': 0.34241474654377885, 'support': 51}, 'weighted avg': {'precision': 0.45914020923126736, 'recall': 0.5098039215686274, 'f1-score': 0.48140959609650313, 'support': 51}, 'samples avg': {'precision': 0.494047619047619, 'recall': 0.5023809523809524, 'f1-score': 0.4622448979591836, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 465/1450 [04:13<19:22,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8, 0, Loss: 0.022853605449199677\n",
      "Precision (Macro): 0.3440656565656566, Recall (Macro): 0.27912087912087913\n",
      "F1 Score (Micro): 0.4545454545454546, F1 Score (Macro): 0.30202676439557996\n",
      "{'IGT': {'precision': 0.5555555555555556, 'recall': 0.35714285714285715, 'f1-score': 0.43478260869565216, 'support': 14}, 'IFG_ADA': {'precision': 0.7272727272727273, 'recall': 0.5, 'f1-score': 0.5925925925925926, 'support': 16}, 'IFG_WHO': {'precision': 0.4375, 'recall': 0.5384615384615384, 'f1-score': 0.4827586206896552, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5405405405405406, 'recall': 0.39215686274509803, 'f1-score': 0.4545454545454546, 'support': 51}, 'macro avg': {'precision': 0.3440656565656566, 'recall': 0.27912087912087913, 'f1-score': 0.30202676439557996, 'support': 51}, 'weighted avg': {'precision': 0.4921890473361062, 'recall': 0.39215686274509803, 'f1-score': 0.42831960925855156, 'support': 51}, 'samples avg': {'precision': 0.47619047619047616, 'recall': 0.4029761904761905, 'f1-score': 0.3833333333333333, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 490/1450 [04:25<18:08,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8, 25, Loss: 0.013748697005212307\n",
      "Precision (Macro): 0.3388888888888889, Recall (Macro): 0.33090659340659345\n",
      "F1 Score (Micro): 0.5106382978723404, F1 Score (Macro): 0.3337194570135747\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.42857142857142855, 'f1-score': 0.4615384615384615, 'support': 14}, 'IFG_ADA': {'precision': 0.6111111111111112, 'recall': 0.6875, 'f1-score': 0.6470588235294118, 'support': 16}, 'IFG_WHO': {'precision': 0.5833333333333334, 'recall': 0.5384615384615384, 'f1-score': 0.5599999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5581395348837209, 'recall': 0.47058823529411764, 'f1-score': 0.5106382978723404, 'support': 51}, 'macro avg': {'precision': 0.3388888888888889, 'recall': 0.33090659340659345, 'f1-score': 0.3337194570135747, 'support': 51}, 'weighted avg': {'precision': 0.4776688453159042, 'recall': 0.47058823529411764, 'f1-score': 0.4724407772158637, 'support': 51}, 'samples avg': {'precision': 0.5178571428571429, 'recall': 0.47559523809523807, 'f1-score': 0.45612244897959187, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 515/1450 [04:37<17:42,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8, 50, Loss: 0.004161322023719549\n",
      "Precision (Macro): 0.3174242424242424, Recall (Macro): 0.41195054945054943\n",
      "F1 Score (Micro): 0.5504587155963303, F1 Score (Macro): 0.3522222222222222\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.7857142857142857, 'f1-score': 0.6111111111111112, 'support': 14}, 'IFG_ADA': {'precision': 0.5416666666666666, 'recall': 0.8125, 'f1-score': 0.65, 'support': 16}, 'IFG_WHO': {'precision': 0.5454545454545454, 'recall': 0.46153846153846156, 'f1-score': 0.4999999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5172413793103449, 'recall': 0.5882352941176471, 'f1-score': 0.5504587155963303, 'support': 51}, 'macro avg': {'precision': 0.3174242424242424, 'recall': 0.41195054945054943, 'f1-score': 0.3522222222222222, 'support': 51}, 'weighted avg': {'precision': 0.44622697563874036, 'recall': 0.5882352941176471, 'f1-score': 0.4991285403050109, 'support': 51}, 'samples avg': {'precision': 0.49999999999999994, 'recall': 0.6214285714285713, 'f1-score': 0.5062925170068027, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 523/1450 [04:42<18:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9, 0, Loss: 0.0048269289545714855\n",
      "Precision (Macro): 0.3277777777777778, Recall (Macro): 0.37554945054945055\n",
      "F1 Score (Micro): 0.5294117647058824, F1 Score (Macro): 0.3472941176470588\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.7142857142857143, 'f1-score': 0.588235294117647, 'support': 14}, 'IFG_ADA': {'precision': 0.5555555555555556, 'recall': 0.625, 'f1-score': 0.5882352941176471, 'support': 16}, 'IFG_WHO': {'precision': 0.5833333333333334, 'recall': 0.5384615384615384, 'f1-score': 0.5599999999999999, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5294117647058824, 'recall': 0.5294117647058824, 'f1-score': 0.5294117647058824, 'support': 51}, 'macro avg': {'precision': 0.3277777777777778, 'recall': 0.37554945054945055, 'f1-score': 0.3472941176470588, 'support': 51}, 'weighted avg': {'precision': 0.460239651416122, 'recall': 0.5294117647058824, 'f1-score': 0.48876585928489047, 'support': 51}, 'samples avg': {'precision': 0.4761904761904762, 'recall': 0.5142857142857143, 'f1-score': 0.45136054421768707, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 548/1450 [04:54<17:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9, 25, Loss: 0.09769488871097565\n",
      "Precision (Macro): 0.30476190476190473, Recall (Macro): 0.2726648351648352\n",
      "F1 Score (Micro): 0.4395604395604396, F1 Score (Macro): 0.2749189189189189\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.21428571428571427, 'f1-score': 0.3, 'support': 14}, 'IFG_ADA': {'precision': 0.5238095238095238, 'recall': 0.6875, 'f1-score': 0.5945945945945946, 'support': 16}, 'IFG_WHO': {'precision': 0.5, 'recall': 0.46153846153846156, 'f1-score': 0.48000000000000004, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5, 'recall': 0.39215686274509803, 'f1-score': 0.4395604395604396, 'support': 51}, 'macro avg': {'precision': 0.30476190476190473, 'recall': 0.2726648351648352, 'f1-score': 0.2749189189189189, 'support': 51}, 'weighted avg': {'precision': 0.4290382819794584, 'recall': 0.39215686274509803, 'f1-score': 0.3912453630100689, 'support': 51}, 'samples avg': {'precision': 0.4523809523809524, 'recall': 0.4148809523809524, 'f1-score': 0.39999999999999997, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 573/1450 [05:06<16:34,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9, 50, Loss: 0.036249369382858276\n",
      "Precision (Macro): 0.3226655697243932, Recall (Macro): 0.30590659340659343\n",
      "F1 Score (Micro): 0.4731182795698925, F1 Score (Macro): 0.31278321678321674\n",
      "{'IGT': {'precision': 0.5454545454545454, 'recall': 0.42857142857142855, 'f1-score': 0.4799999999999999, 'support': 14}, 'IFG_ADA': {'precision': 0.5294117647058824, 'recall': 0.5625, 'f1-score': 0.5454545454545455, 'support': 16}, 'IFG_WHO': {'precision': 0.5384615384615384, 'recall': 0.5384615384615384, 'f1-score': 0.5384615384615384, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5238095238095238, 'recall': 0.43137254901960786, 'f1-score': 0.4731182795698925, 'support': 51}, 'macro avg': {'precision': 0.3226655697243932, 'recall': 0.30590659340659343, 'f1-score': 0.31278321678321674, 'support': 51}, 'weighted avg': {'precision': 0.4530774876795638, 'recall': 0.43137254901960786, 'f1-score': 0.44014260249554366, 'support': 51}, 'samples avg': {'precision': 0.48214285714285715, 'recall': 0.43273809523809526, 'f1-score': 0.41428571428571426, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 581/1450 [05:11<17:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, 0, Loss: 0.00991807971149683\n",
      "Precision (Macro): 0.30658119658119654, Recall (Macro): 0.3023351648351648\n",
      "F1 Score (Micro): 0.45833333333333326, F1 Score (Macro): 0.29947974730583427\n",
      "{'IGT': {'precision': 0.4444444444444444, 'recall': 0.2857142857142857, 'f1-score': 0.34782608695652173, 'support': 14}, 'IFG_ADA': {'precision': 0.55, 'recall': 0.6875, 'f1-score': 0.6111111111111112, 'support': 16}, 'IFG_WHO': {'precision': 0.5384615384615384, 'recall': 0.5384615384615384, 'f1-score': 0.5384615384615384, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.4888888888888889, 'recall': 0.43137254901960786, 'f1-score': 0.45833333333333326, 'support': 51}, 'macro avg': {'precision': 0.30658119658119654, 'recall': 0.3023351648351648, 'f1-score': 0.29947974730583427, 'support': 51}, 'weighted avg': {'precision': 0.4318082788671024, 'recall': 0.43137254901960786, 'f1-score': 0.4244577057876291, 'support': 51}, 'samples avg': {'precision': 0.48214285714285715, 'recall': 0.4505952380952381, 'f1-score': 0.42380952380952375, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 606/1450 [05:23<16:42,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, 25, Loss: 0.06130741909146309\n",
      "Precision (Macro): 0.35578947368421054, Recall (Macro): 0.2726648351648352\n",
      "F1 Score (Micro): 0.46511627906976744, F1 Score (Macro): 0.29322000653808433\n",
      "{'IGT': {'precision': 0.6, 'recall': 0.21428571428571427, 'f1-score': 0.3157894736842105, 'support': 14}, 'IFG_ADA': {'precision': 0.5789473684210527, 'recall': 0.6875, 'f1-score': 0.6285714285714286, 'support': 16}, 'IFG_WHO': {'precision': 0.6, 'recall': 0.46153846153846156, 'f1-score': 0.5217391304347826, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5714285714285714, 'recall': 0.39215686274509803, 'f1-score': 0.46511627906976744, 'support': 51}, 'macro avg': {'precision': 0.35578947368421054, 'recall': 0.2726648351648352, 'f1-score': 0.29322000653808433, 'support': 51}, 'weighted avg': {'precision': 0.49927760577915375, 'recall': 0.39215686274509803, 'f1-score': 0.4168785134190976, 'support': 51}, 'samples avg': {'precision': 0.5178571428571429, 'recall': 0.4148809523809524, 'f1-score': 0.4297619047619047, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 631/1450 [05:35<15:31,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, 50, Loss: 0.009206756018102169\n",
      "Precision (Macro): 0.2824248120300752, Recall (Macro): 0.27843406593406594\n",
      "F1 Score (Micro): 0.4301075268817204, F1 Score (Macro): 0.26964285714285713\n",
      "{'IGT': {'precision': 0.42857142857142855, 'recall': 0.21428571428571427, 'f1-score': 0.2857142857142857, 'support': 14}, 'IFG_ADA': {'precision': 0.5625, 'recall': 0.5625, 'f1-score': 0.5625, 'support': 16}, 'IFG_WHO': {'precision': 0.42105263157894735, 'recall': 0.6153846153846154, 'f1-score': 0.5, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.47619047619047616, 'recall': 0.39215686274509803, 'f1-score': 0.4301075268817204, 'support': 51}, 'macro avg': {'precision': 0.2824248120300752, 'recall': 0.27843406593406594, 'f1-score': 0.26964285714285713, 'support': 51}, 'weighted avg': {'precision': 0.40144478844169246, 'recall': 0.39215686274509803, 'f1-score': 0.38235294117647056, 'support': 51}, 'samples avg': {'precision': 0.4523809523809524, 'recall': 0.3791666666666667, 'f1-score': 0.37261904761904757, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 639/1450 [05:41<15:56,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11, 0, Loss: 0.005336794536560774\n",
      "Precision (Macro): 0.33476923076923076, Recall (Macro): 0.4\n",
      "F1 Score (Micro): 0.5490196078431373, F1 Score (Macro): 0.3508906365530685\n",
      "{'IGT': {'precision': 0.5384615384615384, 'recall': 0.5, 'f1-score': 0.5185185185185186, 'support': 14}, 'IFG_ADA': {'precision': 0.6153846153846154, 'recall': 0.5, 'f1-score': 0.5517241379310345, 'support': 16}, 'IFG_WHO': {'precision': 0.52, 'recall': 1.0, 'f1-score': 0.6842105263157895, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5490196078431373, 'recall': 0.5490196078431373, 'f1-score': 0.5490196078431373, 'support': 51}, 'macro avg': {'precision': 0.33476923076923076, 'recall': 0.4, 'f1-score': 0.3508906365530685, 'support': 51}, 'weighted avg': {'precision': 0.4734238310708899, 'recall': 0.5490196078431373, 'f1-score': 0.4898349472208054, 'support': 51}, 'samples avg': {'precision': 0.511904761904762, 'recall': 0.5273809523809524, 'f1-score': 0.4803571428571428, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 664/1450 [05:53<14:50,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11, 25, Loss: 0.0013402992626652122\n",
      "Precision (Macro): 0.33809523809523806, Recall (Macro): 0.32980769230769236\n",
      "F1 Score (Micro): 0.5, F1 Score (Macro): 0.32800982800982803\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 14}, 'IFG_ADA': {'precision': 0.5238095238095238, 'recall': 0.6875, 'f1-score': 0.5945945945945946, 'support': 16}, 'IFG_WHO': {'precision': 0.6666666666666666, 'recall': 0.46153846153846156, 'f1-score': 0.5454545454545455, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5333333333333333, 'recall': 0.47058823529411764, 'f1-score': 0.5, 'support': 51}, 'macro avg': {'precision': 0.33809523809523806, 'recall': 0.32980769230769236, 'f1-score': 0.32800982800982803, 'support': 51}, 'weighted avg': {'precision': 0.4715219421101774, 'recall': 0.47058823529411764, 'f1-score': 0.4628318157729923, 'support': 51}, 'samples avg': {'precision': 0.511904761904762, 'recall': 0.5130952380952382, 'f1-score': 0.47397959183673466, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 689/1450 [06:04<14:23,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11, 50, Loss: 0.008799913339316845\n",
      "Precision (Macro): 0.31007575757575756, Recall (Macro): 0.3070054945054945\n",
      "F1 Score (Micro): 0.4731182795698925, F1 Score (Macro): 0.30678571428571433\n",
      "{'IGT': {'precision': 0.45454545454545453, 'recall': 0.35714285714285715, 'f1-score': 0.4, 'support': 14}, 'IFG_ADA': {'precision': 0.5625, 'recall': 0.5625, 'f1-score': 0.5625, 'support': 16}, 'IFG_WHO': {'precision': 0.5333333333333333, 'recall': 0.6153846153846154, 'f1-score': 0.5714285714285715, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5238095238095238, 'recall': 0.43137254901960786, 'f1-score': 0.4731182795698925, 'support': 51}, 'macro avg': {'precision': 0.31007575757575756, 'recall': 0.3070054945054945, 'f1-score': 0.30678571428571433, 'support': 51}, 'weighted avg': {'precision': 0.43719548425430776, 'recall': 0.43137254901960786, 'f1-score': 0.4319327731092438, 'support': 51}, 'samples avg': {'precision': 0.48214285714285715, 'recall': 0.4238095238095238, 'f1-score': 0.4119047619047619, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 697/1450 [06:10<14:46,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12, 0, Loss: 0.009115336462855339\n",
      "Precision (Macro): 0.2797979797979798, Recall (Macro): 0.3460164835164835\n",
      "F1 Score (Micro): 0.47058823529411764, F1 Score (Macro): 0.29978835978835977\n",
      "{'IGT': {'precision': 0.4444444444444444, 'recall': 0.5714285714285714, 'f1-score': 0.5, 'support': 14}, 'IFG_ADA': {'precision': 0.45454545454545453, 'recall': 0.3125, 'f1-score': 0.3703703703703703, 'support': 16}, 'IFG_WHO': {'precision': 0.5, 'recall': 0.8461538461538461, 'f1-score': 0.6285714285714286, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.47058823529411764, 'recall': 0.47058823529411764, 'f1-score': 0.47058823529411764, 'support': 51}, 'macro avg': {'precision': 0.2797979797979798, 'recall': 0.3460164835164835, 'f1-score': 0.29978835978835977, 'support': 51}, 'weighted avg': {'precision': 0.3920578332343038, 'recall': 0.47058823529411764, 'f1-score': 0.41367361759518617, 'support': 51}, 'samples avg': {'precision': 0.5178571428571429, 'recall': 0.46071428571428574, 'f1-score': 0.44421768707482995, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 722/1450 [06:22<13:44,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12, 25, Loss: 0.08784043788909912\n",
      "Precision (Macro): 0.3350250626566416, Recall (Macro): 0.3572802197802198\n",
      "F1 Score (Micro): 0.5199999999999999, F1 Score (Macro): 0.3353691353691354\n",
      "{'IGT': {'precision': 0.5263157894736842, 'recall': 0.7142857142857143, 'f1-score': 0.6060606060606061, 'support': 14}, 'IFG_ADA': {'precision': 0.5238095238095238, 'recall': 0.6875, 'f1-score': 0.5945945945945946, 'support': 16}, 'IFG_WHO': {'precision': 0.625, 'recall': 0.38461538461538464, 'f1-score': 0.4761904761904762, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5306122448979592, 'recall': 0.5098039215686274, 'f1-score': 0.5199999999999999, 'support': 51}, 'macro avg': {'precision': 0.3350250626566416, 'recall': 0.3572802197802198, 'f1-score': 0.3353691353691354, 'support': 51}, 'weighted avg': {'precision': 0.46812496928596004, 'recall': 0.5098039215686274, 'f1-score': 0.4742909448791802, 'support': 51}, 'samples avg': {'precision': 0.5357142857142857, 'recall': 0.5202380952380953, 'f1-score': 0.49438775510204086, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 747/1450 [06:34<13:20,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12, 50, Loss: 0.004711448680609465\n",
      "Precision (Macro): 0.35841001104159, Recall (Macro): 0.34807692307692306\n",
      "F1 Score (Micro): 0.5208333333333333, F1 Score (Macro): 0.35132275132275137\n",
      "{'IGT': {'precision': 0.5384615384615384, 'recall': 0.5, 'f1-score': 0.5185185185185186, 'support': 14}, 'IFG_ADA': {'precision': 0.5263157894736842, 'recall': 0.625, 'f1-score': 0.5714285714285714, 'support': 16}, 'IFG_WHO': {'precision': 0.7272727272727273, 'recall': 0.6153846153846154, 'f1-score': 0.6666666666666667, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5555555555555556, 'recall': 0.49019607843137253, 'f1-score': 0.5208333333333333, 'support': 51}, 'macro avg': {'precision': 0.35841001104159, 'recall': 0.34807692307692306, 'f1-score': 0.35132275132275137, 'support': 51}, 'weighted avg': {'precision': 0.4983148945997243, 'recall': 0.49019607843137253, 'f1-score': 0.49154476605457, 'support': 51}, 'samples avg': {'precision': 0.5654761904761905, 'recall': 0.4934523809523809, 'f1-score': 0.4858843537414966, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 755/1450 [06:39<13:38,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13, 0, Loss: 0.013527425937354565\n",
      "Precision (Macro): 0.3476190476190476, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5346534653465347, F1 Score (Macro): 0.3577297297297298\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6666666666666666, 'recall': 0.6153846153846154, 'f1-score': 0.64, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.54, 'recall': 0.5294117647058824, 'f1-score': 0.5346534653465347, 'support': 51}, 'macro avg': {'precision': 0.3476190476190476, 'recall': 0.3730769230769231, 'f1-score': 0.3577297297297298, 'support': 51}, 'weighted avg': {'precision': 0.4864612511671335, 'recall': 0.5294117647058824, 'f1-score': 0.5038897721250662, 'support': 51}, 'samples avg': {'precision': 0.5416666666666666, 'recall': 0.5470238095238095, 'f1-score': 0.4918367346938775, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 780/1450 [06:51<13:14,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13, 25, Loss: 0.0034740485716611147\n",
      "Precision (Macro): 0.35454545454545455, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5346534653465347, F1 Score (Macro): 0.35964912280701755\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 14}, 'IFG_ADA': {'precision': 0.5454545454545454, 'recall': 0.75, 'f1-score': 0.631578947368421, 'support': 16}, 'IFG_WHO': {'precision': 0.7272727272727273, 'recall': 0.6153846153846154, 'f1-score': 0.6666666666666667, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.54, 'recall': 0.5294117647058824, 'f1-score': 0.5346534653465347, 'support': 51}, 'macro avg': {'precision': 0.35454545454545455, 'recall': 0.3730769230769231, 'f1-score': 0.35964912280701755, 'support': 51}, 'weighted avg': {'precision': 0.4937611408199643, 'recall': 0.5294117647058824, 'f1-score': 0.5053319573443412, 'support': 51}, 'samples avg': {'precision': 0.5416666666666666, 'recall': 0.5470238095238095, 'f1-score': 0.501360544217687, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 805/1450 [07:03<12:13,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13, 50, Loss: 0.002381500555202365\n",
      "Precision (Macro): 0.3341880341880342, Recall (Macro): 0.34807692307692306\n",
      "F1 Score (Micro): 0.5208333333333333, F1 Score (Macro): 0.3407239819004525\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 14}, 'IFG_ADA': {'precision': 0.5555555555555556, 'recall': 0.625, 'f1-score': 0.5882352941176471, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5555555555555556, 'recall': 0.49019607843137253, 'f1-score': 0.5208333333333333, 'support': 51}, 'macro avg': {'precision': 0.3341880341880342, 'recall': 0.34807692307692306, 'f1-score': 0.3407239819004525, 'support': 51}, 'weighted avg': {'precision': 0.4684095860566449, 'recall': 0.49019607843137253, 'f1-score': 0.47866205305651677, 'support': 51}, 'samples avg': {'precision': 0.5238095238095238, 'recall': 0.47559523809523807, 'f1-score': 0.45612244897959175, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 813/1450 [07:08<12:29,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14, 0, Loss: 0.0015538003062829375\n",
      "Precision (Macro): 0.33076923076923076, Recall (Macro): 0.3248626373626374\n",
      "F1 Score (Micro): 0.49462365591397855, F1 Score (Macro): 0.3262953138815208\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.5714285714285714, 'f1-score': 0.5333333333333333, 'support': 14}, 'IFG_ADA': {'precision': 0.5384615384615384, 'recall': 0.4375, 'f1-score': 0.4827586206896552, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5476190476190477, 'recall': 0.45098039215686275, 'f1-score': 0.49462365591397855, 'support': 51}, 'macro avg': {'precision': 0.33076923076923076, 'recall': 0.3248626373626374, 'f1-score': 0.3262953138815208, 'support': 51}, 'weighted avg': {'precision': 0.4630467571644042, 'recall': 0.45098039215686275, 'f1-score': 0.4547216587784539, 'support': 51}, 'samples avg': {'precision': 0.5238095238095238, 'recall': 0.42797619047619045, 'f1-score': 0.43112244897959184, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 838/1450 [07:20<11:32,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14, 25, Loss: 0.0018082000315189362\n",
      "Precision (Macro): 0.3409523809523809, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.54, F1 Score (Macro): 0.35428145386766074\n",
      "{'IGT': {'precision': 0.4666666666666667, 'recall': 0.5, 'f1-score': 0.4827586206896552, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6666666666666666, 'recall': 0.6153846153846154, 'f1-score': 0.64, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5510204081632653, 'recall': 0.5294117647058824, 'f1-score': 0.54, 'support': 51}, 'macro avg': {'precision': 0.3409523809523809, 'recall': 0.3730769230769231, 'f1-score': 0.35428145386766074, 'support': 51}, 'weighted avg': {'precision': 0.47731092436974787, 'recall': 0.5294117647058824, 'f1-score': 0.4991568444712461, 'support': 51}, 'samples avg': {'precision': 0.5595238095238095, 'recall': 0.5470238095238095, 'f1-score': 0.5037414965986394, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 863/1450 [07:32<11:04,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14, 50, Loss: 0.0008875567582435906\n",
      "Precision (Macro): 0.3373626373626374, Recall (Macro): 0.3587912087912088\n",
      "F1 Score (Micro): 0.5306122448979591, F1 Score (Macro): 0.34511434511434513\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.42857142857142855, 'f1-score': 0.4615384615384615, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5531914893617021, 'recall': 0.5098039215686274, 'f1-score': 0.5306122448979591, 'support': 51}, 'macro avg': {'precision': 0.3373626373626374, 'recall': 0.3587912087912088, 'f1-score': 0.34511434511434513, 'support': 51}, 'weighted avg': {'precision': 0.4733893557422969, 'recall': 0.5098039215686274, 'f1-score': 0.48705719293954586, 'support': 51}, 'samples avg': {'precision': 0.5773809523809523, 'recall': 0.5398809523809524, 'f1-score': 0.507142857142857, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 871/1450 [07:38<11:20,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15, 0, Loss: 0.0016329229110851884\n",
      "Precision (Macro): 0.32967032967032966, Recall (Macro): 0.3587912087912088\n",
      "F1 Score (Micro): 0.5252525252525253, F1 Score (Macro): 0.3416955416955417\n",
      "{'IGT': {'precision': 0.46153846153846156, 'recall': 0.42857142857142855, 'f1-score': 0.4444444444444445, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5416666666666666, 'recall': 0.5098039215686274, 'f1-score': 0.5252525252525253, 'support': 51}, 'macro avg': {'precision': 0.32967032967032966, 'recall': 0.3587912087912088, 'f1-score': 0.3416955416955417, 'support': 51}, 'weighted avg': {'precision': 0.46283128636069815, 'recall': 0.5098039215686274, 'f1-score': 0.4823647176588353, 'support': 51}, 'samples avg': {'precision': 0.5595238095238095, 'recall': 0.5398809523809524, 'f1-score': 0.4952380952380952, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 896/1450 [07:49<10:28,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15, 25, Loss: 0.0021268357522785664\n",
      "Precision (Macro): 0.3248626373626374, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5294117647058824, F1 Score (Macro): 0.34613998613998614\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5294117647058824, 'recall': 0.5294117647058824, 'f1-score': 0.5294117647058824, 'support': 51}, 'macro avg': {'precision': 0.3248626373626374, 'recall': 0.3730769230769231, 'f1-score': 0.34613998613998614, 'support': 51}, 'weighted avg': {'precision': 0.45623249299719887, 'recall': 0.5294117647058824, 'f1-score': 0.488464935523759, 'support': 51}, 'samples avg': {'precision': 0.5297619047619048, 'recall': 0.5470238095238095, 'f1-score': 0.4846938775510204, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 921/1450 [08:01<09:59,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15, 50, Loss: 0.0011512538185343146\n",
      "Precision (Macro): 0.3248626373626374, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5294117647058824, F1 Score (Macro): 0.34613998613998614\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5294117647058824, 'recall': 0.5294117647058824, 'f1-score': 0.5294117647058824, 'support': 51}, 'macro avg': {'precision': 0.3248626373626374, 'recall': 0.3730769230769231, 'f1-score': 0.34613998613998614, 'support': 51}, 'weighted avg': {'precision': 0.45623249299719887, 'recall': 0.5294117647058824, 'f1-score': 0.488464935523759, 'support': 51}, 'samples avg': {'precision': 0.5297619047619048, 'recall': 0.5470238095238095, 'f1-score': 0.48469387755102034, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 929/1450 [08:07<10:39,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16, 0, Loss: 0.000804257404524833\n",
      "Precision (Macro): 0.3248626373626374, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5346534653465347, F1 Score (Macro): 0.34613998613998614\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.54, 'recall': 0.5294117647058824, 'f1-score': 0.5346534653465347, 'support': 51}, 'macro avg': {'precision': 0.3248626373626374, 'recall': 0.3730769230769231, 'f1-score': 0.34613998613998614, 'support': 51}, 'weighted avg': {'precision': 0.45623249299719887, 'recall': 0.5294117647058824, 'f1-score': 0.488464935523759, 'support': 51}, 'samples avg': {'precision': 0.5357142857142857, 'recall': 0.5470238095238095, 'f1-score': 0.48945578231292514, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 954/1450 [08:19<09:22,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16, 25, Loss: 0.0011578518897294998\n",
      "Precision (Macro): 0.3248626373626374, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5346534653465347, F1 Score (Macro): 0.34613998613998614\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.54, 'recall': 0.5294117647058824, 'f1-score': 0.5346534653465347, 'support': 51}, 'macro avg': {'precision': 0.3248626373626374, 'recall': 0.3730769230769231, 'f1-score': 0.34613998613998614, 'support': 51}, 'weighted avg': {'precision': 0.45623249299719887, 'recall': 0.5294117647058824, 'f1-score': 0.488464935523759, 'support': 51}, 'samples avg': {'precision': 0.5357142857142857, 'recall': 0.5470238095238095, 'f1-score': 0.4894557823129252, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 979/1450 [08:31<08:54,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16, 50, Loss: 0.0006348168826662004\n",
      "Precision (Macro): 0.3196678321678322, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5294117647058824, F1 Score (Macro): 0.3427260458839406\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5454545454545454, 'recall': 0.75, 'f1-score': 0.631578947368421, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5294117647058824, 'recall': 0.5294117647058824, 'f1-score': 0.5294117647058824, 'support': 51}, 'macro avg': {'precision': 0.3196678321678322, 'recall': 0.3730769230769231, 'f1-score': 0.3427260458839406, 'support': 51}, 'weighted avg': {'precision': 0.4480837789661319, 'recall': 0.5294117647058824, 'f1-score': 0.483109735122119, 'support': 51}, 'samples avg': {'precision': 0.5178571428571429, 'recall': 0.5470238095238095, 'f1-score': 0.48707482993197276, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 987/1450 [08:36<09:08,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 17, 0, Loss: 0.0004730406799353659\n",
      "Precision (Macro): 0.31533882783882783, Recall (Macro): 0.3605769230769231\n",
      "F1 Score (Micro): 0.5148514851485149, F1 Score (Macro): 0.33532917532917533\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5238095238095238, 'recall': 0.6875, 'f1-score': 0.5945945945945946, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.52, 'recall': 0.5098039215686274, 'f1-score': 0.5148514851485149, 'support': 51}, 'macro avg': {'precision': 0.31533882783882783, 'recall': 0.3605769230769231, 'f1-score': 0.33532917532917533, 'support': 51}, 'weighted avg': {'precision': 0.44129318394024275, 'recall': 0.5098039215686274, 'f1-score': 0.4715068009185656, 'support': 51}, 'samples avg': {'precision': 0.5119047619047619, 'recall': 0.5291666666666667, 'f1-score': 0.47636054421768703, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1012/1450 [08:48<08:15,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 17, 25, Loss: 0.0013535817852243781\n",
      "Precision (Macro): 0.3196678321678322, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5294117647058824, F1 Score (Macro): 0.3427260458839406\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5454545454545454, 'recall': 0.75, 'f1-score': 0.631578947368421, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5294117647058824, 'recall': 0.5294117647058824, 'f1-score': 0.5294117647058824, 'support': 51}, 'macro avg': {'precision': 0.3196678321678322, 'recall': 0.3730769230769231, 'f1-score': 0.3427260458839406, 'support': 51}, 'weighted avg': {'precision': 0.4480837789661319, 'recall': 0.5294117647058824, 'f1-score': 0.483109735122119, 'support': 51}, 'samples avg': {'precision': 0.5178571428571429, 'recall': 0.5470238095238095, 'f1-score': 0.4870748299319727, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1037/1450 [09:00<07:48,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 17, 50, Loss: 0.0016087247058749199\n",
      "Precision (Macro): 0.3205769230769231, Recall (Macro): 0.3605769230769231\n",
      "F1 Score (Micro): 0.5199999999999999, F1 Score (Macro): 0.3386324786324787\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.55, 'recall': 0.6875, 'f1-score': 0.6111111111111112, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5306122448979592, 'recall': 0.5098039215686274, 'f1-score': 0.5199999999999999, 'support': 51}, 'macro avg': {'precision': 0.3205769230769231, 'recall': 0.3605769230769231, 'f1-score': 0.3386324786324787, 'support': 51}, 'weighted avg': {'precision': 0.44950980392156864, 'recall': 0.5098039215686274, 'f1-score': 0.47668845315904135, 'support': 51}, 'samples avg': {'precision': 0.5238095238095238, 'recall': 0.5291666666666667, 'f1-score': 0.48350340136054415, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1045/1450 [09:05<07:58,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 18, 0, Loss: 0.0006119388854131103\n",
      "Precision (Macro): 0.3205769230769231, Recall (Macro): 0.3605769230769231\n",
      "F1 Score (Micro): 0.5199999999999999, F1 Score (Macro): 0.3386324786324787\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.55, 'recall': 0.6875, 'f1-score': 0.6111111111111112, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5306122448979592, 'recall': 0.5098039215686274, 'f1-score': 0.5199999999999999, 'support': 51}, 'macro avg': {'precision': 0.3205769230769231, 'recall': 0.3605769230769231, 'f1-score': 0.3386324786324787, 'support': 51}, 'weighted avg': {'precision': 0.44950980392156864, 'recall': 0.5098039215686274, 'f1-score': 0.47668845315904135, 'support': 51}, 'samples avg': {'precision': 0.5238095238095238, 'recall': 0.5291666666666667, 'f1-score': 0.4835034013605442, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1070/1450 [09:17<07:11,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 18, 25, Loss: 0.0008757466566748917\n",
      "Precision (Macro): 0.3205769230769231, Recall (Macro): 0.3605769230769231\n",
      "F1 Score (Micro): 0.5199999999999999, F1 Score (Macro): 0.3386324786324787\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.55, 'recall': 0.6875, 'f1-score': 0.6111111111111112, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5306122448979592, 'recall': 0.5098039215686274, 'f1-score': 0.5199999999999999, 'support': 51}, 'macro avg': {'precision': 0.3205769230769231, 'recall': 0.3605769230769231, 'f1-score': 0.3386324786324787, 'support': 51}, 'weighted avg': {'precision': 0.44950980392156864, 'recall': 0.5098039215686274, 'f1-score': 0.47668845315904135, 'support': 51}, 'samples avg': {'precision': 0.5238095238095238, 'recall': 0.5291666666666667, 'f1-score': 0.4835034013605442, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1095/1450 [09:29<06:54,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 18, 50, Loss: 0.00040179523057304323\n",
      "Precision (Macro): 0.33083333333333337, Recall (Macro): 0.3605769230769231\n",
      "F1 Score (Micro): 0.5252525252525253, F1 Score (Macro): 0.3435555555555556\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.55, 'recall': 0.6875, 'f1-score': 0.6111111111111112, 'support': 16}, 'IFG_WHO': {'precision': 0.6666666666666666, 'recall': 0.6153846153846154, 'f1-score': 0.64, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5416666666666666, 'recall': 0.5098039215686274, 'f1-score': 0.5252525252525253, 'support': 51}, 'macro avg': {'precision': 0.33083333333333337, 'recall': 0.3605769230769231, 'f1-score': 0.3435555555555556, 'support': 51}, 'weighted avg': {'precision': 0.46258169934640525, 'recall': 0.5098039215686274, 'f1-score': 0.4829629629629629, 'support': 51}, 'samples avg': {'precision': 0.5416666666666666, 'recall': 0.5291666666666667, 'f1-score': 0.49540816326530607, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1103/1450 [09:35<06:51,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 19, 0, Loss: 0.0006135634030215442\n",
      "Precision (Macro): 0.33083333333333337, Recall (Macro): 0.3605769230769231\n",
      "F1 Score (Micro): 0.5252525252525253, F1 Score (Macro): 0.3435555555555556\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.55, 'recall': 0.6875, 'f1-score': 0.6111111111111112, 'support': 16}, 'IFG_WHO': {'precision': 0.6666666666666666, 'recall': 0.6153846153846154, 'f1-score': 0.64, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5416666666666666, 'recall': 0.5098039215686274, 'f1-score': 0.5252525252525253, 'support': 51}, 'macro avg': {'precision': 0.33083333333333337, 'recall': 0.3605769230769231, 'f1-score': 0.3435555555555556, 'support': 51}, 'weighted avg': {'precision': 0.46258169934640525, 'recall': 0.5098039215686274, 'f1-score': 0.4829629629629629, 'support': 51}, 'samples avg': {'precision': 0.5416666666666666, 'recall': 0.5291666666666667, 'f1-score': 0.4954081632653061, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1128/1450 [09:46<06:04,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 19, 25, Loss: 0.012120909057557583\n",
      "Precision (Macro): 0.3248626373626374, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5346534653465347, F1 Score (Macro): 0.34613998613998614\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.54, 'recall': 0.5294117647058824, 'f1-score': 0.5346534653465347, 'support': 51}, 'macro avg': {'precision': 0.3248626373626374, 'recall': 0.3730769230769231, 'f1-score': 0.34613998613998614, 'support': 51}, 'weighted avg': {'precision': 0.45623249299719887, 'recall': 0.5294117647058824, 'f1-score': 0.488464935523759, 'support': 51}, 'samples avg': {'precision': 0.5297619047619048, 'recall': 0.5470238095238095, 'f1-score': 0.49421768707482994, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1153/1450 [09:58<05:36,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 19, 50, Loss: 0.0007430381374433637\n",
      "Precision (Macro): 0.3314802844214609, Recall (Macro): 0.3873626373626374\n",
      "F1 Score (Micro): 0.5490196078431373, F1 Score (Macro): 0.3560324592582657\n",
      "{'IGT': {'precision': 0.47058823529411764, 'recall': 0.5714285714285714, 'f1-score': 0.5161290322580646, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5490196078431373, 'recall': 0.5490196078431373, 'f1-score': 0.5490196078431373, 'support': 51}, 'macro avg': {'precision': 0.3314802844214609, 'recall': 0.3873626373626374, 'f1-score': 0.3560324592582657, 'support': 51}, 'weighted avg': {'precision': 0.4653155379798979, 'recall': 0.5490196078431373, 'f1-score': 0.5020428398037506, 'support': 51}, 'samples avg': {'precision': 0.5297619047619048, 'recall': 0.5648809523809524, 'f1-score': 0.5061224489795918, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1161/1450 [10:04<05:41,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20, 0, Loss: 0.0017106671584770083\n",
      "Precision (Macro): 0.3314802844214609, Recall (Macro): 0.3873626373626374\n",
      "F1 Score (Micro): 0.5490196078431373, F1 Score (Macro): 0.3560324592582657\n",
      "{'IGT': {'precision': 0.47058823529411764, 'recall': 0.5714285714285714, 'f1-score': 0.5161290322580646, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5490196078431373, 'recall': 0.5490196078431373, 'f1-score': 0.5490196078431373, 'support': 51}, 'macro avg': {'precision': 0.3314802844214609, 'recall': 0.3873626373626374, 'f1-score': 0.3560324592582657, 'support': 51}, 'weighted avg': {'precision': 0.4653155379798979, 'recall': 0.5490196078431373, 'f1-score': 0.5020428398037506, 'support': 51}, 'samples avg': {'precision': 0.5297619047619048, 'recall': 0.5648809523809524, 'f1-score': 0.5061224489795919, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1186/1450 [10:16<04:59,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20, 25, Loss: 0.000552975048776716\n",
      "Precision (Macro): 0.3248626373626374, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.5346534653465347, F1 Score (Macro): 0.34613998613998614\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.75, 'f1-score': 0.6486486486486486, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.54, 'recall': 0.5294117647058824, 'f1-score': 0.5346534653465347, 'support': 51}, 'macro avg': {'precision': 0.3248626373626374, 'recall': 0.3730769230769231, 'f1-score': 0.34613998613998614, 'support': 51}, 'weighted avg': {'precision': 0.45623249299719887, 'recall': 0.5294117647058824, 'f1-score': 0.488464935523759, 'support': 51}, 'samples avg': {'precision': 0.5297619047619048, 'recall': 0.5470238095238095, 'f1-score': 0.49421768707482994, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 1211/1450 [10:27<04:31,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20, 50, Loss: 0.0033386684954166412\n",
      "Precision (Macro): 0.3305769230769231, Recall (Macro): 0.3730769230769231\n",
      "F1 Score (Micro): 0.54, F1 Score (Macro): 0.34974358974358977\n",
      "{'IGT': {'precision': 0.4375, 'recall': 0.5, 'f1-score': 0.4666666666666667, 'support': 14}, 'IFG_ADA': {'precision': 0.6, 'recall': 0.75, 'f1-score': 0.6666666666666665, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5510204081632653, 'recall': 0.5294117647058824, 'f1-score': 0.54, 'support': 51}, 'macro avg': {'precision': 0.3305769230769231, 'recall': 0.3730769230769231, 'f1-score': 0.34974358974358977, 'support': 51}, 'weighted avg': {'precision': 0.46519607843137256, 'recall': 0.5294117647058824, 'f1-score': 0.49411764705882344, 'support': 51}, 'samples avg': {'precision': 0.5476190476190476, 'recall': 0.5470238095238095, 'f1-score': 0.49659863945578225, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1219/1450 [10:33<04:31,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 21, 0, Loss: 0.0008103453437797725\n",
      "Precision (Macro): 0.3371945701357466, Recall (Macro): 0.3873626373626374\n",
      "F1 Score (Micro): 0.5544554455445545, F1 Score (Macro): 0.3596360628618693\n",
      "{'IGT': {'precision': 0.47058823529411764, 'recall': 0.5714285714285714, 'f1-score': 0.5161290322580646, 'support': 14}, 'IFG_ADA': {'precision': 0.6, 'recall': 0.75, 'f1-score': 0.6666666666666665, 'support': 16}, 'IFG_WHO': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.56, 'recall': 0.5490196078431373, 'f1-score': 0.5544554455445545, 'support': 51}, 'macro avg': {'precision': 0.3371945701357466, 'recall': 0.3873626373626374, 'f1-score': 0.3596360628618693, 'support': 51}, 'weighted avg': {'precision': 0.4742791234140715, 'recall': 0.5490196078431373, 'f1-score': 0.507695551338815, 'support': 51}, 'samples avg': {'precision': 0.5476190476190476, 'recall': 0.5648809523809524, 'f1-score': 0.5085034013605443, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1244/1450 [10:45<03:53,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 21, 25, Loss: 0.007571869995445013\n",
      "Precision (Macro): 0.33666666666666667, Recall (Macro): 0.2923076923076923\n",
      "F1 Score (Micro): 0.3950617283950617, F1 Score (Macro): 0.3120401337792642\n",
      "{'IGT': {'precision': 0.5833333333333334, 'recall': 0.5, 'f1-score': 0.5384615384615384, 'support': 14}, 'IFG_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16}, 'IFG_WHO': {'precision': 0.6, 'recall': 0.46153846153846156, 'f1-score': 0.5217391304347826, 'support': 13}, 'HbA1c_ADA': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5333333333333333, 'recall': 0.3137254901960784, 'f1-score': 0.3950617283950617, 'support': 51}, 'macro avg': {'precision': 0.33666666666666667, 'recall': 0.2923076923076923, 'f1-score': 0.3120401337792642, 'support': 51}, 'weighted avg': {'precision': 0.3718954248366013, 'recall': 0.3137254901960784, 'f1-score': 0.3396288281198767, 'support': 51}, 'samples avg': {'precision': 0.42261904761904756, 'recall': 0.33749999999999997, 'f1-score': 0.3345238095238095, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1269/1450 [10:57<03:24,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 21, 50, Loss: 0.7363214492797852\n",
      "Precision (Macro): 0.24846153846153846, Recall (Macro): 0.2978021978021978\n",
      "F1 Score (Micro): 0.46511627906976744, F1 Score (Macro): 0.2666666666666667\n",
      "{'IGT': {'precision': 0.6923076923076923, 'recall': 0.6428571428571429, 'f1-score': 0.6666666666666666, 'support': 14}, 'IFG_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 16}, 'IFG_WHO': {'precision': 0.55, 'recall': 0.8461538461538461, 'f1-score': 0.6666666666666667, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5714285714285714, 'recall': 0.39215686274509803, 'f1-score': 0.46511627906976744, 'support': 51}, 'macro avg': {'precision': 0.24846153846153846, 'recall': 0.2978021978021978, 'f1-score': 0.2666666666666667, 'support': 51}, 'weighted avg': {'precision': 0.3302413273001508, 'recall': 0.39215686274509803, 'f1-score': 0.35294117647058826, 'support': 51}, 'samples avg': {'precision': 0.4345238095238095, 'recall': 0.3833333333333333, 'f1-score': 0.37993197278911556, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1277/1450 [11:02<03:32,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 22, 0, Loss: 0.00510635320097208\n",
      "Precision (Macro): 0.32304347826086954, Recall (Macro): 0.4424450549450549\n",
      "F1 Score (Micro): 0.5740740740740741, F1 Score (Macro): 0.3672072072072072\n",
      "{'IGT': {'precision': 0.5652173913043478, 'recall': 0.9285714285714286, 'f1-score': 0.7027027027027025, 'support': 14}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.4375, 'f1-score': 0.4666666666666667, 'support': 16}, 'IFG_WHO': {'precision': 0.55, 'recall': 0.8461538461538461, 'f1-score': 0.6666666666666667, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.543859649122807, 'recall': 0.6078431372549019, 'f1-score': 0.5740740740740741, 'support': 51}, 'macro avg': {'precision': 0.32304347826086954, 'recall': 0.4424450549450549, 'f1-score': 0.3672072072072072, 'support': 51}, 'weighted avg': {'precision': 0.4522165387894288, 'recall': 0.6078431372549019, 'f1-score': 0.509238650415121, 'support': 51}, 'samples avg': {'precision': 0.5238095238095238, 'recall': 0.5750000000000001, 'f1-score': 0.5160714285714285, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1302/1450 [11:14<02:47,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 22, 25, Loss: 0.0019145839614793658\n",
      "Precision (Macro): 0.3339958592132505, Recall (Macro): 0.3427197802197802\n",
      "F1 Score (Micro): 0.5154639175257731, F1 Score (Macro): 0.3238095238095238\n",
      "{'IGT': {'precision': 0.5714285714285714, 'recall': 0.2857142857142857, 'f1-score': 0.38095238095238093, 'support': 14}, 'IFG_ADA': {'precision': 0.5652173913043478, 'recall': 0.8125, 'f1-score': 0.6666666666666667, 'support': 16}, 'IFG_WHO': {'precision': 0.5333333333333333, 'recall': 0.6153846153846154, 'f1-score': 0.5714285714285715, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5434782608695652, 'recall': 0.49019607843137253, 'f1-score': 0.5154639175257731, 'support': 51}, 'macro avg': {'precision': 0.3339958592132505, 'recall': 0.3427197802197802, 'f1-score': 0.3238095238095238, 'support': 51}, 'weighted avg': {'precision': 0.47013356067064505, 'recall': 0.49019607843137253, 'f1-score': 0.4593837535014006, 'support': 51}, 'samples avg': {'precision': 0.4880952380952381, 'recall': 0.5160714285714285, 'f1-score': 0.45714285714285713, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1327/1450 [11:26<02:19,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 22, 50, Loss: 0.0012460543075576425\n",
      "Precision (Macro): 0.3344537815126051, Recall (Macro): 0.2927197802197802\n",
      "F1 Score (Micro): 0.4666666666666667, F1 Score (Macro): 0.30379990379990385\n",
      "{'IGT': {'precision': 0.5714285714285714, 'recall': 0.2857142857142857, 'f1-score': 0.38095238095238093, 'support': 14}, 'IFG_ADA': {'precision': 0.5294117647058824, 'recall': 0.5625, 'f1-score': 0.5454545454545455, 'support': 16}, 'IFG_WHO': {'precision': 0.5714285714285714, 'recall': 0.6153846153846154, 'f1-score': 0.5925925925925927, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5384615384615384, 'recall': 0.4117647058823529, 'f1-score': 0.4666666666666667, 'support': 51}, 'macro avg': {'precision': 0.3344537815126051, 'recall': 0.2927197802197802, 'f1-score': 0.30379990379990385, 'support': 51}, 'weighted avg': {'precision': 0.46861097380128514, 'recall': 0.4117647058823529, 'f1-score': 0.42675117184921113, 'support': 51}, 'samples avg': {'precision': 0.44642857142857145, 'recall': 0.39107142857142857, 'f1-score': 0.3773809523809523, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1335/1450 [11:31<02:15,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 23, 0, Loss: 0.001648056204430759\n",
      "Precision (Macro): 0.3236601307189543, Recall (Macro): 0.3070054945054945\n",
      "F1 Score (Micro): 0.46808510638297873, F1 Score (Macro): 0.3103331451157539\n",
      "{'IGT': {'precision': 0.5555555555555556, 'recall': 0.35714285714285715, 'f1-score': 0.43478260869565216, 'support': 14}, 'IFG_ADA': {'precision': 0.5294117647058824, 'recall': 0.5625, 'f1-score': 0.5454545454545455, 'support': 16}, 'IFG_WHO': {'precision': 0.5333333333333333, 'recall': 0.6153846153846154, 'f1-score': 0.5714285714285715, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5116279069767442, 'recall': 0.43137254901960786, 'f1-score': 0.46808510638297873, 'support': 51}, 'macro avg': {'precision': 0.3236601307189543, 'recall': 0.3070054945054945, 'f1-score': 0.3103331451157539, 'support': 51}, 'weighted avg': {'precision': 0.4545431244393182, 'recall': 0.43137254901960786, 'f1-score': 0.4361333466192802, 'support': 51}, 'samples avg': {'precision': 0.44642857142857145, 'recall': 0.42678571428571427, 'f1-score': 0.38333333333333336, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1360/1450 [11:43<01:42,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 23, 25, Loss: 0.0006035125115886331\n",
      "Precision (Macro): 0.33066666666666666, Recall (Macro): 0.3712912087912088\n",
      "F1 Score (Micro): 0.5294117647058824, F1 Score (Macro): 0.3411149825783973\n",
      "{'IGT': {'precision': 0.6, 'recall': 0.42857142857142855, 'f1-score': 0.5, 'support': 14}, 'IFG_ADA': {'precision': 0.52, 'recall': 0.8125, 'f1-score': 0.6341463414634146, 'support': 16}, 'IFG_WHO': {'precision': 0.5333333333333333, 'recall': 0.6153846153846154, 'f1-score': 0.5714285714285715, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5294117647058824, 'recall': 0.5294117647058824, 'f1-score': 0.5294117647058824, 'support': 51}, 'macro avg': {'precision': 0.33066666666666666, 'recall': 0.3712912087912088, 'f1-score': 0.3411149825783973, 'support': 51}, 'weighted avg': {'precision': 0.4637908496732026, 'recall': 0.5294117647058824, 'f1-score': 0.481861037097766, 'support': 51}, 'samples avg': {'precision': 0.5059523809523809, 'recall': 0.5875, 'f1-score': 0.4928571428571428, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1385/1450 [11:55<01:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 23, 50, Loss: 0.2159060537815094\n",
      "Precision (Macro): 0.34206349206349207, Recall (Macro): 0.34807692307692306\n",
      "F1 Score (Micro): 0.5208333333333333, F1 Score (Macro): 0.3438578850343556\n",
      "{'IGT': {'precision': 0.5833333333333334, 'recall': 0.5, 'f1-score': 0.5384615384615384, 'support': 14}, 'IFG_ADA': {'precision': 0.5555555555555556, 'recall': 0.625, 'f1-score': 0.5882352941176471, 'support': 16}, 'IFG_WHO': {'precision': 0.5714285714285714, 'recall': 0.6153846153846154, 'f1-score': 0.5925925925925927, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5555555555555556, 'recall': 0.49019607843137253, 'f1-score': 0.5208333333333333, 'support': 51}, 'macro avg': {'precision': 0.34206349206349207, 'recall': 0.34807692307692306, 'f1-score': 0.3438578850343556, 'support': 51}, 'weighted avg': {'precision': 0.4800809212573918, 'recall': 0.49019607843137253, 'f1-score': 0.4834103911381882, 'support': 51}, 'samples avg': {'precision': 0.5297619047619048, 'recall': 0.5476190476190476, 'f1-score': 0.49761904761904757, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1393/1450 [12:01<01:07,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24, 0, Loss: 0.0019202486146241426\n",
      "Precision (Macro): 0.36190476190476184, Recall (Macro): 0.2802197802197802\n",
      "F1 Score (Micro): 0.47058823529411764, F1 Score (Macro): 0.31085714285714283\n",
      "{'IGT': {'precision': 0.5714285714285714, 'recall': 0.2857142857142857, 'f1-score': 0.38095238095238093, 'support': 14}, 'IFG_ADA': {'precision': 0.5714285714285714, 'recall': 0.5, 'f1-score': 0.5333333333333333, 'support': 16}, 'IFG_WHO': {'precision': 0.6666666666666666, 'recall': 0.6153846153846154, 'f1-score': 0.64, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5882352941176471, 'recall': 0.39215686274509803, 'f1-score': 0.47058823529411764, 'support': 51}, 'macro avg': {'precision': 0.36190476190476184, 'recall': 0.2802197802197802, 'f1-score': 0.31085714285714283, 'support': 51}, 'weighted avg': {'precision': 0.5060690943043884, 'recall': 0.39215686274509803, 'f1-score': 0.43503267973856213, 'support': 51}, 'samples avg': {'precision': 0.5238095238095238, 'recall': 0.45535714285714285, 'f1-score': 0.4523809523809524, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1418/1450 [12:13<00:37,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24, 25, Loss: 0.0023294638376682997\n",
      "Precision (Macro): 0.3233766233766234, Recall (Macro): 0.34093406593406594\n",
      "F1 Score (Micro): 0.49484536082474223, F1 Score (Macro): 0.3250544662309368\n",
      "{'IGT': {'precision': 0.5, 'recall': 0.7142857142857143, 'f1-score': 0.588235294117647, 'support': 14}, 'IFG_ADA': {'precision': 0.5454545454545454, 'recall': 0.375, 'f1-score': 0.4444444444444444, 'support': 16}, 'IFG_WHO': {'precision': 0.5714285714285714, 'recall': 0.6153846153846154, 'f1-score': 0.5925925925925927, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.5217391304347826, 'recall': 0.47058823529411764, 'f1-score': 0.49484536082474223, 'support': 51}, 'macro avg': {'precision': 0.3233766233766234, 'recall': 0.34093406593406594, 'f1-score': 0.3250544662309368, 'support': 51}, 'weighted avg': {'precision': 0.4540361599185128, 'recall': 0.47058823529411764, 'f1-score': 0.4519629202443505, 'support': 51}, 'samples avg': {'precision': 0.5119047619047619, 'recall': 0.4654761904761905, 'f1-score': 0.44404761904761897, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1443/1450 [12:24<00:07,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24, 50, Loss: 0.02743689715862274\n",
      "Precision (Macro): 0.2866666666666667, Recall (Macro): 0.2802197802197802\n",
      "F1 Score (Micro): 0.4301075268817204, F1 Score (Macro): 0.28095238095238095\n",
      "{'IGT': {'precision': 0.4, 'recall': 0.2857142857142857, 'f1-score': 0.3333333333333333, 'support': 14}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 16}, 'IFG_WHO': {'precision': 0.5333333333333333, 'recall': 0.6153846153846154, 'f1-score': 0.5714285714285715, 'support': 13}, 'HbA1c_ADA': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 6}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}, 'micro avg': {'precision': 0.47619047619047616, 'recall': 0.39215686274509803, 'f1-score': 0.4301075268817204, 'support': 51}, 'macro avg': {'precision': 0.2866666666666667, 'recall': 0.2802197802197802, 'f1-score': 0.28095238095238095, 'support': 51}, 'weighted avg': {'precision': 0.40261437908496733, 'recall': 0.39215686274509803, 'f1-score': 0.39402427637721754, 'support': 51}, 'samples avg': {'precision': 0.4404761904761904, 'recall': 0.431547619047619, 'f1-score': 0.40238095238095234, 'support': 51}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1450/1450 [12:27<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "biogpt_model = biogpt_train(\n",
    "    DEVICE,\n",
    "    MODEL, \n",
    "    OUTPUT_DIR, \n",
    "    TRAIN_LOADER, \n",
    "    DEV_LOADER, \n",
    "    NUM_LABELS, \n",
    "    NUM_EPOCHS, \n",
    "    LEARNING_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5f0beff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joemenke/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IGT': {'precision': 0.5, 'recall': 0.38095238095238093, 'f1-score': 0.4324324324324324, 'support': 21}, 'IFG_ADA': {'precision': 0.5, 'recall': 0.5416666666666666, 'f1-score': 0.52, 'support': 24}, 'IFG_WHO': {'precision': 0.631578947368421, 'recall': 0.631578947368421, 'f1-score': 0.631578947368421, 'support': 19}, 'HbA1c_ADA': {'precision': 0.5, 'recall': 0.1, 'f1-score': 0.16666666666666669, 'support': 10}, 'HbA1c_IEC': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}, 'micro avg': {'precision': 0.5396825396825397, 'recall': 0.44155844155844154, 'f1-score': 0.48571428571428565, 'support': 77}, 'macro avg': {'precision': 0.42631578947368426, 'recall': 0.33083959899749377, 'f1-score': 0.35013560929350407, 'support': 77}, 'weighted avg': {'precision': 0.512987012987013, 'recall': 0.44155844155844154, 'f1-score': 0.45750321750321754, 'support': 77}, 'samples avg': {'precision': 0.45454545454545453, 'recall': 0.5098484848484849, 'f1-score': 0.4503787878787879, 'support': 77}}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_preds = torch.tensor((), device='cuda:0')\n",
    "    pred_labels = torch.tensor((), device='cuda:0')\n",
    "    for idx, batch in enumerate(TEST_LOADER):\n",
    "        batch.pop('text')\n",
    "        batch['labels'] = torch.transpose(torch.stack(batch['labels'], dim=0), 0, 1)\n",
    "        labels = batch.pop('labels').to(torch.float).to(device)\n",
    "        batch['input_ids'] = torch.transpose(torch.stack(batch['input_ids'], dim=0), 0, 1)\n",
    "        batch['attention_mask'] = torch.transpose(torch.stack(batch['attention_mask'], dim=0), 0, 1)\n",
    "        for key, value in batch.items():\n",
    "            batch[key] = batch[key].to(device)\n",
    "        logits = biogpt_model(**batch).logits\n",
    "        predictions = torch.sigmoid(logits) > 0.5\n",
    "        predictions = predictions.type(torch.LongTensor).cpu().to(device='cuda:0')\n",
    "        all_preds = torch.cat((all_preds, predictions))\n",
    "        pred_labels = torch.cat((pred_labels, labels))\n",
    "        \n",
    "    all_labels = ['IGT', 'IFG_ADA', 'IFG_WHO', 'HbA1c_ADA', 'HbA1c_IEC']\n",
    "    clf_dict = metrics.classification_report(pred_labels.cpu(), all_preds.cpu(), target_names=all_labels,\n",
    "                                             zero_division=0, output_dict=True)\n",
    "    print(clf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f789e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
